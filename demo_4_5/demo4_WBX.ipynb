{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f6ada1e",
   "metadata": {},
   "source": [
    "# üåç Demo 4: Putting the Forecast to the Test\n",
    "\n",
    "## üß† Learning Objectives\n",
    "- Use the `weatherbench2` Python library for forecast verification.\n",
    "- Load forecast and ERA5 data for comparison.\n",
    "- Compute standard metrics including RMSE and ACC.\n",
    "- Focus evaluation on specific countries or regions.\n",
    "- Visualize how forecast skill changes with lead time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b57250",
   "metadata": {},
   "source": [
    "## üéØ Objective\n",
    "\n",
    "In this demo, we scientifically **grade the forecast**, using professional tools like `weatherbenchX`. \n",
    "\n",
    "You‚Äôll compute metrics like RMSE and ACC over custom regions (like Kenya or Chile), visualize model skill, and learn why localized forecasts can be powerful.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ade685",
   "metadata": {},
   "source": [
    "### Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646ff876",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import apache_beam as beam\n",
    "import weatherbenchX\n",
    "from weatherbenchX.data_loaders import xarray_loaders\n",
    "from weatherbenchX.metrics import deterministic\n",
    "from weatherbenchX import aggregation\n",
    "from weatherbenchX import weighting\n",
    "from weatherbenchX import binning\n",
    "from weatherbenchX import time_chunks\n",
    "from weatherbenchX import beam_pipeline\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import warnings\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import glob\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.getLogger(\"apache_beam\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1f09cf",
   "metadata": {},
   "source": [
    "### Define global variables\n",
    "\n",
    "These will be used throughout the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2ec9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define domains and variables\n",
    "DOMAIN_DEFINITIONS = {\n",
    "    \"Global\": {\n",
    "        \"latitude\": (90, -90),\n",
    "        \"longitude\": (0, 360),\n",
    "    },\n",
    "    \"Northern Hemisphere\": {\n",
    "        \"latitude\": (90, 0),\n",
    "        \"longitude\": (0, 360),\n",
    "    },\n",
    "    \"Tropics\": {\n",
    "        \"latitude\": (23.5, -23.5),\n",
    "        \"longitude\": (0, 360),\n",
    "    },\n",
    "    \"Bangladesh\": {\n",
    "        \"latitude\": (26.7, 20.7),\n",
    "        \"longitude\": (88.0, 92.7),\n",
    "    },\n",
    "    \"Chile\": {\n",
    "        \"latitude\": (-17.5, -56.0),\n",
    "        \"longitude\": (284.0, 294.0),\n",
    "    },\n",
    "    \"Nigeria\": {\n",
    "        \"latitude\": (14.7, 4.0),\n",
    "        \"longitude\": (2.7, 14.7),\n",
    "    },\n",
    "    \"Ethiopia\": {\n",
    "        \"latitude\": (14.9, 3.4),\n",
    "        \"longitude\": (33.0, 48.0),\n",
    "    },\n",
    "    \"Kenya\": {\n",
    "        \"latitude\": (5.0, -4.7),\n",
    "        \"longitude\": (33.9, 41.9),\n",
    "    },\n",
    "}\n",
    "VARIABLES = [\"2m_temperature\", \"total_precipitation_6hr\", \"z_500\"]\n",
    "\n",
    "# Load climatology\n",
    "def load_clim():\n",
    "    var_map = {\n",
    "    \"z_500\": \"geopotential\",\n",
    "    }\n",
    "    clim_path     = \"gs://weatherbench2/datasets/era5-hourly-climatology/1990-2019_6h_64x32_equiangular_conservative.zarr\"\n",
    "    clim = xr.open_zarr(clim_path, decode_timedelta=True)\n",
    "    clim_var_map = {v: k for k, v in var_map.items()}\n",
    "\n",
    "    clim = clim.rename_vars(clim_var_map)\n",
    "    clim = clim[VARIABLES]\n",
    "    clim[\"z_500\"] = clim[\"z_500\"].sel(level=500).drop_vars(\"level\")\n",
    "    return clim\n",
    "\n",
    "CLIM = load_clim().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b8d875",
   "metadata": {},
   "source": [
    "### Define core benchmarking functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc1d788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main WBX Benchmarking function\n",
    "def run_benchmark(model_name):\n",
    "\n",
    "    # Model paths\n",
    "    if model_name.lower() == \"graphcast\":\n",
    "        forecast_path = \"gs://weatherbench2/datasets/graphcast/2020/date_range_2019-11-16_2021-02-01_12_hours-64x32_equiangular_conservative.zarr\"\n",
    "    elif model_name.lower() == \"fuxi\":\n",
    "        forecast_path = \"gs://weatherbench2/datasets/fuxi/2020-64x32_equiangular_conservative.zarr\"\n",
    "    elif model_name.lower() == \"ifs\":\n",
    "        forecast_path = \"gs://weatherbench2/datasets/hres/2016-2022-0012-64x32_equiangular_conservative.zarr\"\n",
    "    target_path   = \"gs://weatherbench2/datasets/era5/1959-2023_01_10-6h-64x32_equiangular_conservative.zarr\"\n",
    "\n",
    "    # Preprocessing function to extract 500hPa geopotential height\n",
    "    def preprocess_forecast(ds):\n",
    "        if \"geopotential\" in ds.data_vars and \"level\" in ds[\"geopotential\"].dims:\n",
    "            ds[\"z_500\"] = ds[\"geopotential\"].sel(level=500).drop_vars(\"level\")\n",
    "        return ds\n",
    "    ds = xr.open_zarr(forecast_path, decode_timedelta=True)\n",
    "\n",
    "    # Define init time date range\n",
    "    start = pd.Timestamp(\"2020-01-01T00:00:00\")\n",
    "    end   = pd.Timestamp(\"2020-12-31T00:00:00\")\n",
    "\n",
    "    # Get matching init times (Mondays and Thursdays in 2020)\n",
    "    available_inits = pd.to_datetime(ds[\"time\"].values)\n",
    "    mask_in_range = (available_inits >= start) & (available_inits < end)\n",
    "    mask_weekday = available_inits.weekday.isin([0, 3])\n",
    "    mask = mask_in_range & mask_weekday\n",
    "\n",
    "    selected_inits_pd = available_inits[mask]\n",
    "    init_times = selected_inits_pd.values.astype(\"datetime64[ns]\")\n",
    "\n",
    "    # Define lead times (0 to 240 hours in 24-hour increments)\n",
    "    desired_lead_hours = np.arange(0, 241, 24)\n",
    "    lead_times = desired_lead_hours.astype(\"timedelta64[h]\").astype(\"timedelta64[ns]\")\n",
    "\n",
    "    available_leads = ds[\"prediction_timedelta\"].values\n",
    "    lead_times = np.array([lt for lt in lead_times if lt in available_leads], dtype=\"timedelta64[ns]\")\n",
    "    lead_times_hr = lead_times.astype(\"timedelta64[h]\")\n",
    "\n",
    "    print(f\"Benchmarking model: {model_name}\")\n",
    "    print(f\"Selected {len(init_times)} init times (Mondays & Thursdays between {start} and {end}):\")\n",
    "    print(init_times[:6], \"...\" if len(init_times) > 6 else \"\")\n",
    "    print(\"Lead times (hours):\", lead_times.astype(\"timedelta64[h]\"))\n",
    "\n",
    "    # Begin WBX Benchmarking Pipeline\n",
    "    \n",
    "    # Define data loaders for forecasts and targets\n",
    "    forecast_loader = xarray_loaders.PredictionsFromXarray(\n",
    "        path=forecast_path,\n",
    "        variables=VARIABLES,\n",
    "        rename_dimensions='ecmwf',\n",
    "        preprocessing_fn=preprocess_forecast\n",
    "    )\n",
    "\n",
    "    target_loader = xarray_loaders.TargetsFromXarray(\n",
    "        path=target_path,\n",
    "        variables=VARIABLES,\n",
    "        rename_dimensions='ecmwf',\n",
    "        preprocessing_fn=preprocess_forecast\n",
    "    )\n",
    "\n",
    "    # Define evaluation times\n",
    "    times = time_chunks.TimeChunks(\n",
    "        init_times=init_times,\n",
    "        lead_times=lead_times,\n",
    "        init_time_chunk_size=len(init_times),\n",
    "        lead_time_chunk_size=len(lead_times)\n",
    "    )\n",
    "\n",
    "    # Define metrics of interest\n",
    "    metrics = {\n",
    "    'rmse': deterministic.RMSE(),\n",
    "    'acc': deterministic.ACC(climatology=CLIM),\n",
    "    }\n",
    "\n",
    "    # Use the regions defined above for spatial binning\n",
    "    regions = {name: ((bounds['latitude'][1], bounds['latitude'][0]), (bounds['longitude'][0], bounds['longitude'][1])) for name, bounds in DOMAIN_DEFINITIONS.items()}\n",
    "    bin_by = [binning.Regions(regions)]\n",
    "\n",
    "    # Weight by grid cell area to avoid bias towards poles\n",
    "    weigh_by = [weighting.GridAreaWeighting()]\n",
    "\n",
    "    # Define aggregator to reduce over init_time, latitude, and longitude\n",
    "    # Aggregator will incorporate binning and weighting\n",
    "    aggregator = aggregation.Aggregator(\n",
    "    reduce_dims=['init_time', 'latitude', 'longitude'],\n",
    "    bin_by=bin_by,\n",
    "    weigh_by=weigh_by,\n",
    "    )\n",
    "\n",
    "    # Define output path and filename\n",
    "    if not os.path.exists('benchmark_results'):\n",
    "        os.makedirs('benchmark_results')\n",
    "    metrics_fname = \"_\".join(sorted(metrics.keys()))\n",
    "    # Output filename format: wbx_{model}_{metrics}_{num_inits}_{min_lead}hr_{max_lead}hr.nc\n",
    "    out_fname = f\"wbx_{model_name.lower()}_{metrics_fname}_{len(init_times)}_{min(lead_times_hr).astype(int)}hr_{max(lead_times_hr).astype(int)}hr.nc\"\n",
    "    out_path = f\"benchmark_results/{out_fname}\"\n",
    "    if os.path.exists(out_path):\n",
    "        print(\"Pipeline finished. Check:\", out_path)\n",
    "        return out_path\n",
    "\n",
    "    # Beam is a tool for parallel processing, useful for large datasets\n",
    "    # Here we use the DirectRunner for simplicity; for larger datasets consider DataflowRunner or others\n",
    "    root = beam.Pipeline(runner=\"DirectRunner\")\n",
    "    beam_pipeline.define_pipeline(\n",
    "        root=root,\n",
    "        times=times,\n",
    "        predictions_loader=forecast_loader,\n",
    "        targets_loader=target_loader,\n",
    "        metrics=metrics,\n",
    "        aggregator=aggregator,\n",
    "        out_path=out_path,\n",
    "    )\n",
    "\n",
    "    # Run the pipeline\n",
    "    result = root.run()\n",
    "    result.wait_until_finish()\n",
    "\n",
    "    print(\"Pipeline finished. Check:\", out_path)\n",
    "    return out_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b7da54",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_paths = {}\n",
    "models = ['GraphCast', 'FuXi', 'IFS']\n",
    "\n",
    "for model in models:\n",
    "    out_path = run_benchmark(model)\n",
    "    out_paths[model] = out_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98c1b32",
   "metadata": {},
   "source": [
    "## View the benchmark results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37004071",
   "metadata": {},
   "outputs": [],
   "source": [
    "wbx_results = {}\n",
    "\n",
    "try:\n",
    "    print(\"Loading results...\")\n",
    "    for model, out_path in out_paths.items():\n",
    "        wbx_results[model] = xr.open_dataset(out_path).compute()\n",
    "        display(wbx_results[model])\n",
    "except Exception as _:\n",
    "    print(\"Loading results...\")\n",
    "    out_paths = glob.glob('benchmark_results/wbx_*.nc')\n",
    "    for out_path in out_paths:\n",
    "        model = out_path.split('/')[1].split('_')[1]\n",
    "        wbx_results[model] = xr.open_dataset(out_path).compute()\n",
    "        print(f\"Loaded {model} results from {out_path}\")\n",
    "        display(wbx_results[model])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b66c359",
   "metadata": {},
   "source": [
    "## Plot the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c319d774",
   "metadata": {},
   "source": [
    "### Plotting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eff1ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric_over_region(wbx_results, region, metric, variable):\n",
    "    plt.figure(figsize=(8, 4), dpi=100)\n",
    "    for model, wbx_results in wbx_results.items():\n",
    "        plt.plot(\n",
    "            wbx_results['lead_time'].values.astype('timedelta64[h]').astype(int)//24,\n",
    "            wbx_results[f\"{metric}.{variable}\"].sel(region=region),\n",
    "            label=model\n",
    "        )\n",
    "    if (metric == 'acc' or metric == 'ACC'):\n",
    "        plt.ylim(0, 1)\n",
    "        plt.axhline(0.6, color='gray', linestyle='--')\n",
    "    else:\n",
    "        plt.ylim(bottom=0)\n",
    "\n",
    "    plt.title(f\"{variable} {metric.upper()} over {region} in 2020 (ERA5 ground truth)\")\n",
    "    plt.xlabel(\"Lead time (days)\")\n",
    "    plt.ylabel(metric.upper())\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c306409",
   "metadata": {},
   "source": [
    "### Select region, metrics, variable to include within the plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd29784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define items to plot \n",
    "region = 'Global'   # options:\n",
    "                        # 'Global', 'Northern Hemisphere', 'Tropics', \n",
    "                        # 'Bangladesh', 'Chile', 'Nigeria', 'Ethiopia', 'Kenya'\n",
    "\n",
    "metric =  'acc' # options: 'rmse', 'acc'\n",
    "\n",
    "variable = '2m_temperature' # options: '2m_temperature', 'total_precipitation_6hr', 'z_500'\n",
    "\n",
    "plot_metric_over_region(wbx_results, region, metric, variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6b3283",
   "metadata": {},
   "source": [
    "### Discussion Questions\n",
    "\n",
    "Examine the plot:  \n",
    "What do you notice? Which model is the best at a 5-day lead time?  \n",
    "Which model is the best at the final lead time?  \n",
    "Is the relative skill between models consistent with lead time? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77606385",
   "metadata": {},
   "source": [
    "## Plot the results, but aggregated by lead time instead of time\n",
    "\n",
    "Here we will use GraphCast as a test case. Other models will produce similar patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e8609f",
   "metadata": {},
   "source": [
    "### Setup code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dad43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map dropdown keys -> possible variable names in the Zarrs\n",
    "VAR_MAP = {\n",
    "    \"2t\":   [\"2m_temperature\", \"2t\", \"t2m\"],\n",
    "    \"tp6h\": [\"total_precipitation_6hr\", \"total_precipitation\", \"tp\"],\n",
    "    \"z500\": [\"z_500\", \"z500\", \"geopotential\"],\n",
    "}\n",
    "\n",
    "DOMAIN_SLICES = {\n",
    "    \"Global\": {\n",
    "        \"latitude\": slice(90, -90),\n",
    "        \"longitude\": slice(0, 360),\n",
    "    },\n",
    "    \"Northern Hemisphere\": {\n",
    "        \"latitude\": slice(90, 0),\n",
    "        \"longitude\": slice(0, 360),\n",
    "    },\n",
    "    \"Tropics\": {\n",
    "        \"latitude\": slice(23.5, -23.5),\n",
    "        \"longitude\": slice(0, 360),\n",
    "    },\n",
    "    \"Bangladesh\": {\n",
    "        \"latitude\": slice(26.7, 20.7),\n",
    "        \"longitude\": slice(88.0, 92.7),\n",
    "    },\n",
    "    \"Chile\": {\n",
    "        \"latitude\": slice(-17.5, -56.0),\n",
    "        \"longitude\": slice(284.0, 294.0),\n",
    "    },\n",
    "    \"Nigeria\": {\n",
    "        \"latitude\": slice(14.7, 4.0),\n",
    "        \"longitude\": slice(2.7, 14.7),\n",
    "    },\n",
    "    \"Ethiopia\": {\n",
    "        \"latitude\": slice(14.9, 3.4),\n",
    "        \"longitude\": slice(33.0, 48.0),\n",
    "    },\n",
    "    \"Kenya\": {\n",
    "        \"latitude\": slice(5.0, -4.7),\n",
    "        \"longitude\": slice(33.9, 41.9),\n",
    "    },\n",
    "}\n",
    "\n",
    "def _pick_var(ds, candidates):\n",
    "    for v in candidates:\n",
    "        if v in ds.data_vars:\n",
    "            return v\n",
    "    raise KeyError(f\"None of {candidates} found in dataset. Have: {list(ds.data_vars)}\")\n",
    "\n",
    "def _add_z500(ds):\n",
    "    # Create z_500 from 'geopotential' if present with a 'level' dim\n",
    "    if \"geopotential\" in ds.data_vars and \"level\" in ds[\"geopotential\"].dims:\n",
    "        ds[\"z_500\"] = ds[\"geopotential\"].sel(level=500).drop_vars(\"level\")\n",
    "    return ds\n",
    "\n",
    "def _slice_region(ds, region_name):\n",
    "    r = DOMAIN_SLICES[region_name]\n",
    "    lat_name = \"latitude\" if \"latitude\" in ds.coords else \"lat\"\n",
    "    lon_name = \"longitude\" if \"longitude\" in ds.coords else \"lon\"\n",
    "\n",
    "    lat = ds[lat_name]\n",
    "    # Handle both ascending and descending latitude coordinates\n",
    "    if lat[0] > lat[-1]:\n",
    "        lat_slice = slice(r[\"latitude\"].start, r[\"latitude\"].stop)  # descending coord\n",
    "    else:\n",
    "        lat_slice = slice(r[\"latitude\"].stop, r[\"latitude\"].start) if r[\"latitude\"].start > r[\"latitude\"].stop else r[\"latitude\"]\n",
    "\n",
    "    return ds.sel({lat_name: lat_slice, lon_name: r[\"longitude\"]})\n",
    "\n",
    "def load_aligned(forecast_path, target_path, var_key, region_name):\n",
    "    \"\"\"\n",
    "    Returns forecast and target DataArrays over the chosen region with matching\n",
    "    (time, prediction_timedelta, lat, lon). Targets are looked up at valid time = init + lead.\n",
    "    \"\"\"\n",
    "    f = xr.open_zarr(forecast_path, decode_timedelta=True)\n",
    "    t = xr.open_zarr(target_path,   decode_timedelta=True)\n",
    "\n",
    "    f = _add_z500(f)\n",
    "    t = _add_z500(t)\n",
    "\n",
    "    fv = _pick_var(f, VAR_MAP[var_key])\n",
    "    tv = _pick_var(t, VAR_MAP[var_key])\n",
    "\n",
    "    f = _slice_region(f[[fv]], region_name)\n",
    "    t = _slice_region(t[[tv]], region_name)\n",
    "\n",
    "    # Build valid-time matrix (init + lead) and select targets there\n",
    "    # Xarray allows DataArray indexers with matching shape.\n",
    "    valid_time = f[\"time\"] + f[\"prediction_timedelta\"]\n",
    "    try:\n",
    "        t_valid = t[tv].sel(time=valid_time)  # exact match\n",
    "    except Exception:\n",
    "        t_valid = t[tv].sel(time=valid_time, method=\"nearest\", tolerance=np.timedelta64(3, \"h\"))\n",
    "\n",
    "    return f[fv], t_valid.rename(tv), \"prediction_timedelta\"\n",
    "\n",
    "def metric_rmse(f_da, t_da):\n",
    "    \"\"\"\n",
    "    RMSE collapsed over space and lead, returning one value per init time.\n",
    "    \"\"\"\n",
    "    err2 = (f_da - t_da) ** 2\n",
    "    # Average over everything except 'time'\n",
    "    dims_to_mean = [d for d in err2.dims if d not in [\"time\", \"prediction_timedelta\"]]\n",
    "    return np.sqrt(err2.mean(dim=dims_to_mean, skipna=True))\n",
    "# -------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc6e2ba",
   "metadata": {},
   "source": [
    "### Interactive Plotting code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7b7065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Widgets + time-series plot (uses objects/functions defined in earlier cells) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "# Variable keys expected by your helpers (the same ones you used elsewhere)\n",
    "VAR_KEYS = [(\"2t\", \"2t\"), (\"tp6h\", \"tp6h\"), (\"z500\", \"z500\")]\n",
    "\n",
    "# ‚îÄ‚îÄ UI\n",
    "w_region = widgets.Dropdown(options=list(DOMAIN_DEFINITIONS.keys()),\n",
    "                            value=\"Ethiopia\", description=\"Region:\")\n",
    "w_var    = widgets.Dropdown(options=VAR_KEYS, value=\"2t\", description=\"Variable:\")\n",
    "w_run    = widgets.Button(description=\"Run Verification\", button_style=\"success\")\n",
    "w_log    = widgets.Output()\n",
    "\n",
    "ui_box = widgets.VBox([w_region, w_var, w_run, w_log])\n",
    "display(ui_box)\n",
    "\n",
    "def on_run(_):\n",
    "    with w_log:\n",
    "        w_log.clear_output()\n",
    "        print(f\"Selected region: {w_region.value}\")\n",
    "        print(f\"Selected variable: {w_var.value}\")\n",
    "        print(\"Loading data...\")\n",
    "\n",
    "    try:\n",
    "        # Use your previously defined helper to get forecast/target aligned on the same grid/times\n",
    "        forecast_path = \"gs://weatherbench2/datasets/graphcast/2020/date_range_2019-11-16_2021-02-01_12_hours-64x32_equiangular_conservative.zarr\"\n",
    "        target_path   = \"gs://weatherbench2/datasets/era5/1959-2023_01_10-6h-64x32_equiangular_conservative.zarr\"\n",
    "        f, t, lead_name = load_aligned(forecast_path, target_path, w_var.value, w_region.value)\n",
    "\n",
    "        with w_log:\n",
    "            print(\"Computing metrics...\")\n",
    "\n",
    "        # Use your metric helpers (already defined in earlier cells)\n",
    "        series = metric_rmse(f, t)            # returns DataArray with dim 'time' (init times)\n",
    "        ylabel = \"RMSE\"\n",
    "        title_metric = \"RMSE\"\n",
    "\n",
    "        # Plot\n",
    "        times = pd.to_datetime(series[\"time\"].values)\n",
    "        fig, ax = plt.subplots(figsize=(9, 4))\n",
    "        for lt in [240, 120]:\n",
    "            ax.plot(times, series.sel({lead_name: np.timedelta64(lt, 'h')}), label=f'Lead {lt}h')\n",
    "        # ax.plot(times, series.values)\n",
    "        ax.set_title(f\"{title_metric} of {w_var.value} vs Time\")\n",
    "        ax.set_ylabel(ylabel)\n",
    "        ax.set_xlabel(\"Init time (UTC)\")\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "        with w_log:\n",
    "            print(\"Done ‚úÖ\")\n",
    "        display(fig)\n",
    "        plt.close(fig)\n",
    "\n",
    "    except Exception as e:\n",
    "        with w_log:\n",
    "            print(\"‚ùå Error:\", repr(e))\n",
    "\n",
    "w_run.on_click(on_run)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d4f223",
   "metadata": {},
   "source": [
    "### Discussion Questions\n",
    "\n",
    "What patterns do you observe as they relate to skill?   \n",
    "Are there any months that the model shows better skill over other months?  \n",
    "Is there any relationship between the lead time and the months that have increased skill? Or is consistent between lead times?   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "benchmarks_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
