{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb0fe644",
   "metadata": {},
   "source": [
    "\n",
    "# üåç Demo 5: Ground Truth Challenge ‚Äî TAHMO DATA*\n",
    "\n",
    "## üß† Learning Objectives\n",
    "- Use **weatherbenchX** (metrics) + **xarray** to verify forecasts.\n",
    "\n",
    "- Compute **RMSE** and **MAE** (with WeatherbenchX).\n",
    "- Focus evaluation \n",
    "- Visualize skill vs **lead time**.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e77cf18",
   "metadata": {},
   "source": [
    "\n",
    "## üì¶ Environment Requirements\n",
    "If you hit backend errors like xarray not finding `netcdf4`/`h5netcdf`, install the deps:\n",
    "```bash\n",
    "# pip install xarray netCDF4 h5netcdf zarr fsspec gcsfs ipywidgets matplotlib numpy pandas\n",
    "# pip install weatherbenchX xesmf\n",
    "```\n",
    "For public GCS ERA5, we use anonymous access. No credentials needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8208023d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, glob, io, contextlib, logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from weatherbenchX.metrics import deterministic\n",
    "from weatherbenchX.metrics import base as metrics_base\n",
    "\n",
    "plt.rcParams.update({\"figure.dpi\": 130})\n",
    "xr.set_options(keep_attrs=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece560af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- quiet logging helper -------------------------\n",
    "@contextlib.contextmanager\n",
    "def _silence_lib_logs():\n",
    "    names = [\"gcsfs\", \"fsspec\", \"zarr\", \"google.auth\", \"urllib3\"]\n",
    "    old = {n: logging.getLogger(n).level for n in names}\n",
    "    for n in names: logging.getLogger(n).setLevel(logging.CRITICAL)\n",
    "    buf = io.StringIO()\n",
    "    with contextlib.redirect_stderr(buf), contextlib.redirect_stdout(buf):\n",
    "        yield\n",
    "    for n,lvl in old.items(): logging.getLogger(n).setLevel(lvl)\n",
    "\n",
    "# ------------------------- helpers -------------------------\n",
    "def _open_any(path: str):\n",
    "    \"\"\"Open Zarr (local/GCS) or NetCDF quietly; try ADC‚Üíanon‚Üíunconsolidated.\"\"\"\n",
    "    if path.endswith(\".zarr\"):\n",
    "        with _silence_lib_logs():\n",
    "            for token in (\"cloud\", \"anon\", None):\n",
    "                try:\n",
    "                    if token:\n",
    "                        return xr.open_zarr(path, consolidated=True, chunks={}, storage_options={\"token\": token})\n",
    "                    return xr.open_zarr(path, consolidated=False, chunks={})\n",
    "                except Exception:\n",
    "                    continue\n",
    "        raise RuntimeError(f\"Could not open Zarr: {path}\")\n",
    "    return xr.open_dataset(path)\n",
    "\n",
    "def _open_station_nc(path: str) -> xr.Dataset:\n",
    "    ds = xr.open_dataset(path)\n",
    "    # standardize coord names if present\n",
    "    if \"Lat\" in ds.coords: ds = ds.rename({\"Lat\":\"latitude\"})\n",
    "    if \"Lon\" in ds.coords: ds = ds.rename({\"Lon\":\"longitude\"})\n",
    "    if \"Lat\" in ds.dims:   ds = ds.rename({\"Lat\":\"latitude\"})\n",
    "    if \"Lon\" in ds.dims:   ds = ds.rename({\"Lon\":\"longitude\"})\n",
    "    return ds\n",
    "\n",
    "def _find_precip_name(ds: xr.Dataset) -> str|None:\n",
    "    for cand in [\"total_precipitation_24hr\",\"tp_24h\",\"precip\",\"total_precipitation\",\"rr\",\"rain\"]:\n",
    "        if cand in ds.data_vars: return cand\n",
    "    return None\n",
    "\n",
    "def _find_temp_name(ds: xr.Dataset) -> str|None:\n",
    "    for cand in [\"tavg\",\"t2m_mean\",\"daily_mean_temperature\",\"tas_mean\",\"tmean\"]:\n",
    "        if cand in ds.data_vars: return cand\n",
    "    # sometimes tmax/tmin exist; we‚Äôll average later in Cell 2\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdb193a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ------------------------- widgets (loader) -------------------------\n",
    "station_dir_txt = widgets.Text(value=\"/workspace\", description=\"Station folder:\", layout=widgets.Layout(width=\"95%\"))\n",
    "scan_btn   = widgets.Button(description=\"Scan stations\", button_style=\"info\")\n",
    "station_dd = widgets.Dropdown(options=[], description=\"Station file:\", layout=widgets.Layout(width=\"95%\"))\n",
    "\n",
    "era5_t2m_txt = widgets.Text(\n",
    "    value=\"gs://aim4scale_training_25/ground_truth/era5_t2m_1D_1981_2024.zarr\",\n",
    "    description=\"ERA5 t2m:\", layout=widgets.Layout(width=\"95%\"))\n",
    "era5_tp_txt  = widgets.Text(\n",
    "    value=\"gs://aim4scale_training_25/ground_truth/era5_24hr.zarr\",\n",
    "    description=\"ERA5 tp:\", layout=widgets.Layout(width=\"95%\"))\n",
    "imerg_txt    = widgets.Text(\n",
    "    value=\"gs://aim4scale_training_25/ground_truth/IMERG_0p25_2000_2025.zarr\",\n",
    "    description=\"IMERG:\", layout=widgets.Layout(width=\"95%\"))\n",
    "\n",
    "load_btn = widgets.Button(description=\"Load all\", button_style=\"primary\")\n",
    "out_load = widgets.Output()\n",
    "\n",
    "display(Markdown(\"### üìÑ Pick station (NetCDF) & paths\"),\n",
    "        station_dir_txt, scan_btn, station_dd,\n",
    "        era5_t2m_txt, era5_tp_txt, imerg_txt, load_btn, out_load)\n",
    "\n",
    "# ------------------------- state (shared with later cells) -------------------------\n",
    "ds_station = ds_era5_t2m = ds_era5_tp = ds_imerg = None\n",
    "station_name = \"\"\n",
    "precip_key_station = None\n",
    "temp_key_station   = None\n",
    "\n",
    "# ------------------------- actions -------------------------\n",
    "def _scan(_):\n",
    "    folder = station_dir_txt.value.strip()\n",
    "    files = sorted(glob.glob(os.path.join(folder, \"*.nc\")))\n",
    "    station_dd.options = files\n",
    "    if files: station_dd.value = files[0]\n",
    "scan_btn.on_click(_scan)\n",
    "\n",
    "@out_load.capture(clear_output=True)\n",
    "def _load_all(_):\n",
    "    global ds_station, ds_era5_t2m, ds_era5_tp, ds_imerg, station_name, precip_key_station, temp_key_station\n",
    "    if not station_dd.value:\n",
    "        print(\"‚ùå Pick a station file first (Scan stations).\"); return\n",
    "    try:\n",
    "        with _silence_lib_logs():\n",
    "            ds_station = _open_station_nc(station_dd.value)\n",
    "            ds_era5_t2m = _open_any(era5_t2m_txt.value.strip())\n",
    "            ds_era5_tp  = _open_any(era5_tp_txt.value.strip())\n",
    "            ds_imerg    = _open_any(imerg_txt.value.strip())\n",
    "        station_name = os.path.basename(station_dd.value)\n",
    "        precip_key_station = _find_precip_name(ds_station)\n",
    "        temp_key_station   = _find_temp_name(ds_station)\n",
    "        # summary (quiet ‚Äì no GCS noise)\n",
    "        def _span(ds):\n",
    "            t = \"time\" if \"time\" in ds.coords else \"valid_time\"\n",
    "            return str(pd.to_datetime(ds[t].min().values).date()), str(pd.to_datetime(ds[t].max().values).date())\n",
    "        print(\"‚úÖ All datasets loaded\")\n",
    "        try:\n",
    "            a,b = _span(ds_station); print(f\"‚Ä¢ Station: {station_name} ‚Äî vars: {list(ds_station.data_vars)[:4]} ‚Äî {a} ‚Üí {b}\")\n",
    "            a,b = _span(ds_era5_t2m); print(f\"‚Ä¢ ERA5 t2m: {a} ‚Üí {b}\")\n",
    "            a,b = _span(ds_era5_tp);  print(f\"‚Ä¢ ERA5 tp : {a} ‚Üí {b}\")\n",
    "            a,b = _span(ds_imerg);    print(f\"‚Ä¢ IMERG   : {a} ‚Üí {b}\")\n",
    "        except Exception:\n",
    "            pass\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Load error: {e}\")\n",
    "load_btn.on_click(_load_all)\n",
    "\n",
    "# ------------------------- utilities used by later cells -------------------------\n",
    "def _normalize_precip_mmday(da: xr.DataArray) -> xr.DataArray:\n",
    "    u = (da.attrs.get(\"units\") or da.attrs.get(\"unit\") or \"\").lower()\n",
    "    if u in [\"m\",\"meter\",\"metre\",\"m of water equivalent\"]:\n",
    "        da = da * 1000.0\n",
    "    da.attrs[\"units\"] = \"mm/day\"; return da\n",
    "\n",
    "def _normalize_temp_C(da: xr.DataArray) -> xr.DataArray:\n",
    "    u = (da.attrs.get(\"units\") or da.attrs.get(\"unit\") or \"\").lower()\n",
    "    if \"k\" in u and \"pa\" not in u: da = da - 273.15\n",
    "    da.attrs[\"units\"] = \"¬∞C\"; return da\n",
    "\n",
    "def _coerce_valid_time(da: xr.DataArray) -> xr.DataArray:\n",
    "    if \"valid_time\" in da.dims: return da\n",
    "    if \"time\" in da.dims: return da.rename({\"time\":\"valid_time\"})\n",
    "    dec = xr.decode_cf(da.to_dataset(name=\"_tmp\"), use_cftime=False).to_array(\"_tmp\")\n",
    "    if \"time\" in dec.dims: return dec.rename({\"time\":\"valid_time\"})\n",
    "    raise ValueError(\"No time/valid_time dimension found.\")\n",
    "\n",
    "def _prep_for_wbx_validtime(da: xr.DataArray) -> xr.DataArray:\n",
    "    da = _coerce_valid_time(da)\n",
    "    want = [\"valid_time\"] + [d for d in (\"latitude\",\"longitude\") if d in da.dims]\n",
    "    da = da.transpose(*want)\n",
    "    return da.expand_dims({\"lead_time\":[np.timedelta64(0,\"h\")]})\n",
    "\n",
    "def _wbx_series(pred: xr.DataArray, truth: xr.DataArray, metric: str):\n",
    "    ds_p = xr.Dataset({\"var\": _prep_for_wbx_validtime(pred.astype(\"float32\"))})\n",
    "    ds_t = xr.Dataset({\"var\": _prep_for_wbx_validtime(truth.astype(\"float32\"))})\n",
    "    if metric.upper() == \"RMSE\":\n",
    "        stats = metrics_base.compute_unique_statistics_for_all_metrics({\"rmse\": deterministic.RMSE()}, ds_p, ds_t)\n",
    "        se = stats[\"SquaredError\"][\"var\"]\n",
    "        s  = (se**0.5).mean([d for d in (\"latitude\",\"longitude\") if d in se.dims], skipna=True)\n",
    "        ylabel = \"RMSE\"\n",
    "    else:\n",
    "        stats = metrics_base.compute_unique_statistics_for_all_metrics({\"mae\": deterministic.MAE()}, ds_p, ds_t)\n",
    "        ae = stats[\"AbsoluteError\"][\"var\"]\n",
    "        s  = ae.mean([d for d in (\"latitude\",\"longitude\") if d in ae.dims], skipna=True)\n",
    "        ylabel = \"MAE\"\n",
    "    if \"lead_time\" in s.dims and s.sizes.get(\"lead_time\",1)==1: s = s.isel(lead_time=0)\n",
    "    return s.rename({\"valid_time\":\"time\"}).squeeze(), ylabel\n",
    "\n",
    "def _nearest_on_grid(grid_da: xr.DataArray, lat: float, lon: float) -> xr.DataArray:\n",
    "    if \"longitude\" in grid_da.coords:\n",
    "        g_lon = grid_da[\"longitude\"]\n",
    "        try:\n",
    "            if float(g_lon.min()) < 0: lon = lon % 360.0\n",
    "        except Exception: pass\n",
    "    return grid_da.sel(latitude=lat, longitude=lon, method=\"nearest\")\n",
    "\n",
    "def _to_monthly(series: xr.DataArray, time_dim=\"time\"):\n",
    "    ts = pd.to_datetime(series[time_dim].values)\n",
    "    return series.assign_coords({time_dim: ts}).resample({time_dim:\"MS\"}).mean(skipna=True)\n",
    "\n",
    "def _to_doy_mean(series: xr.DataArray) -> xr.DataArray:\n",
    "    s = series.groupby(\"time.dayofyear\").mean(skipna=True)   # dim = 'dayofyear'\n",
    "    s = s.rename({\"dayofyear\":\"DOY\"})\n",
    "    # ensure coordinate exists & is int (prevents KeyError)\n",
    "    idx = s.indexes[\"DOY\"] if \"DOY\" in s.indexes else np.arange(1, s.sizes.get(\"DOY\",0)+1)\n",
    "    s = s.assign_coords(DOY=(\"DOY\", np.asarray(idx, dtype=int)))\n",
    "    return s\n",
    "\n",
    "def _month_ticks_for_doy(ax):\n",
    "    month_names = [\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\"]\n",
    "    first_doy = [1,32,60,91,121,152,182,213,244,274,305,335]\n",
    "    ax.set_xticks(first_doy); ax.set_xticklabels(month_names)\n",
    "\n",
    "def _time_slice(da: xr.DataArray, y0, m0, y1, m1) -> xr.DataArray:\n",
    "    t0 = np.datetime64(pd.Timestamp(year=y0, month=m0, day=1))\n",
    "    t1 = np.datetime64(pd.Timestamp(year=y1, month=m1, day=1) + pd.offsets.MonthEnd(1))\n",
    "    return da.sel(time=slice(t0, t1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b403dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 2: Station (truth) vs ERA5 (predictor) ===\n",
    "metric_dd_e5 = widgets.Dropdown(options=[\"RMSE\",\"MAE\"], value=\"RMSE\", description=\"Metric:\")\n",
    "# options populated from station vars (fallbacks handled below)\n",
    "var_opts = []\n",
    "if 'temp_key_station' in globals() and temp_key_station: var_opts.append(temp_key_station)\n",
    "if 'precip_key_station' in globals() and precip_key_station: var_opts.append(precip_key_station)\n",
    "var_dd_e5  = widgets.Dropdown(options=(var_opts or [\"tavg\",\"total_precipitation_24hr\"]),\n",
    "                              value=(var_opts[0] if var_opts else \"tavg\"),\n",
    "                              description=\"Variable:\")\n",
    "start_month_e5 = widgets.Dropdown(options=list(range(1,13)), value=1,  description=\"Start M\")\n",
    "end_month_e5   = widgets.Dropdown(options=list(range(1,13)), value=12, description=\"End M\")\n",
    "start_year_e5  = widgets.BoundedIntText(value=2022, min=1900, max=2100, description=\"Start Y\")\n",
    "end_year_e5    = widgets.BoundedIntText(value=2024, min=1900, max=2100, description=\"End Y\")\n",
    "doy_cb_e5      = widgets.Checkbox(value=False, description=\"Group by DOY (month ticks)\")\n",
    "run_btn_e5     = widgets.Button(description=\"Run (Station vs ERA5)\", button_style=\"success\")\n",
    "out_plot_e5    = widgets.Output()\n",
    "\n",
    "display(widgets.HBox([var_dd_e5, metric_dd_e5, doy_cb_e5]),\n",
    "        widgets.HBox([start_month_e5, end_month_e5, start_year_e5, end_year_e5]),\n",
    "        run_btn_e5, out_plot_e5)\n",
    "\n",
    "@out_plot_e5.capture(clear_output=True)\n",
    "def _run_e5(_):\n",
    "    if any(x is None for x in [ds_station, ds_era5_t2m, ds_era5_tp]):\n",
    "        print(\"‚ùå Load data first (Cell 1).\"); return\n",
    "\n",
    "    var, metric = var_dd_e5.value, metric_dd_e5.value\n",
    "    m0, m1 = int(start_month_e5.value), int(end_month_e5.value)\n",
    "    y0, y1 = int(start_year_e5.value),  int(end_year_e5.value)\n",
    "\n",
    "    # station variable + lat/lon\n",
    "    if var in ds_station:\n",
    "        st = ds_station[var]\n",
    "    else:\n",
    "        # tolerant fallbacks\n",
    "        if var.lower().startswith(\"t\"): st = ds_station.get(\"tavg\", None)\n",
    "        else:                           st = ds_station.get(\"total_precipitation_24hr\", None)\n",
    "        if st is None:\n",
    "            print(\"‚ùå Selected variable not found in station file.\"); return\n",
    "    lat = float(st.latitude.values) if \"latitude\" in st.coords and st.latitude.size else float(ds_station.latitude)\n",
    "    lon = float(st.longitude.values) if \"longitude\" in st.coords and st.longitude.size else float(ds_station.longitude)\n",
    "\n",
    "    # normalize & choose ERA5 field\n",
    "    is_precip = (var == precip_key_station) or (\"precip\" in var) or (\"tp\" in var) or (\"rain\" in var)\n",
    "    if is_precip:\n",
    "        st = _normalize_precip_mmday(st)\n",
    "        e5 = _normalize_precip_mmday(ds_era5_tp[\"total_precipitation_24hr\"])\n",
    "    else:\n",
    "        st = _normalize_temp_C(st)\n",
    "        # common ERA5 daily-mean-temperature names\n",
    "        for cand in [\"tavg\",\"t2m_mean\",\"daily_mean_temperature\",\"tas_mean\",\"tmean\"]:\n",
    "            if cand in ds_era5_t2m: e5 = _normalize_temp_C(ds_era5_t2m[cand]); break\n",
    "        else:\n",
    "            if \"tmax\" in ds_era5_t2m and \"tmin\" in ds_era5_t2m:\n",
    "                e5 = _normalize_temp_C((ds_era5_t2m[\"tmax\"] + ds_era5_t2m[\"tmin\"])/2.0)\n",
    "            else:\n",
    "                print(\"‚ùå Could not find ERA5 daily tavg field.\"); return\n",
    "\n",
    "    e5_pt = _nearest_on_grid(e5, lat, lon)\n",
    "\n",
    "    st_s = _time_slice(st,  y0, m0, y1, m1)\n",
    "    e5_s = _time_slice(e5_pt, y0, m0, y1, m1)\n",
    "    if st_s.sizes.get(\"time\",0)==0 or e5_s.sizes.get(\"time\",0)==0:\n",
    "        print(\"‚ö†Ô∏è No data in requested window.\"); return\n",
    "\n",
    "    series, ylab = _wbx_series(e5_s, st_s, metric)\n",
    "\n",
    "    if doy_cb_e5.value:\n",
    "        s = _to_doy_mean(series)\n",
    "        fig, ax = plt.subplots(figsize=(10,4))\n",
    "        s.plot(ax=ax, x=\"DOY\", label=\"ERA5 vs Station\")\n",
    "        _month_ticks_for_doy(ax); ax.set_xlabel(\"month\")\n",
    "    else:\n",
    "        s = _to_monthly(series, \"time\")\n",
    "        fig, ax = plt.subplots(figsize=(10,4))\n",
    "        s.plot(ax=ax, x=\"time\", label=\"ERA5 vs Station\")\n",
    "\n",
    "    units = \"(mm/day)\" if is_precip else \"(¬∞C)\"\n",
    "    ax.set_ylabel(f\"{ylab} {units}\")\n",
    "    title_var = \"PRECIP\" if is_precip else var.upper()\n",
    "    period_txt = f\"{y0}-{y1} ({m0:02d}‚Üí{m1:02d})\"\n",
    "    ax.set_title(f\"{metric} ‚Äî {title_var} ‚Äî Station vs ERA5 ‚Äî {period_txt}\")\n",
    "    ax.grid(True, alpha=0.3); ax.legend(); plt.show()\n",
    "\n",
    "run_btn_e5.on_click(_run_e5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c6ba96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 3: Station (truth) vs IMERG (predictor) ‚Äî precip only ===\n",
    "metric_dd_img = widgets.Dropdown(options=[\"RMSE\",\"MAE\"], value=\"RMSE\", description=\"Metric:\")\n",
    "start_month_img = widgets.Dropdown(options=list(range(1,13)), value=1,  description=\"Start M\")\n",
    "end_month_img   = widgets.Dropdown(options=list(range(1,13)), value=12, description=\"End M\")\n",
    "start_year_img  = widgets.BoundedIntText(value=2022, min=1900, max=2100, description=\"Start Y\")\n",
    "end_year_img    = widgets.BoundedIntText(value=2024, min=1900, max=2100, description=\"End Y\")\n",
    "doy_cb_img      = widgets.Checkbox(value=False, description=\"Group by DOY (month ticks)\")\n",
    "run_btn_img     = widgets.Button(description=\"Run (Station vs IMERG)\", button_style=\"warning\")\n",
    "out_plot_img    = widgets.Output()\n",
    "\n",
    "display(widgets.HBox([metric_dd_img, doy_cb_img]),\n",
    "        widgets.HBox([start_month_img, end_month_img, start_year_img, end_year_img]),\n",
    "        run_btn_img, out_plot_img)\n",
    "\n",
    "@out_plot_img.capture(clear_output=True)\n",
    "def _run_img(_):\n",
    "    if any(x is None for x in [ds_station, ds_imerg]):\n",
    "        print(\"‚ùå Load data first (Cell 1).\"); return\n",
    "    if precip_key_station is None and \"total_precipitation_24hr\" not in ds_station:\n",
    "        print(\"‚ùå Station has no precipitation variable.\"); return\n",
    "\n",
    "    metric = metric_dd_img.value\n",
    "    m0, m1 = int(start_month_img.value), int(end_month_img.value)\n",
    "    y0, y1 = int(start_year_img.value),  int(end_year_img.value)\n",
    "\n",
    "    var = precip_key_station or \"total_precipitation_24hr\"\n",
    "    st = _normalize_precip_mmday(ds_station[var])\n",
    "\n",
    "    lat = float(st.latitude.values) if \"latitude\" in st.coords and st.latitude.size else float(ds_station.latitude)\n",
    "    lon = float(st.longitude.values) if \"longitude\" in st.coords and st.longitude.size else float(ds_station.longitude)\n",
    "\n",
    "    img = _normalize_precip_mmday(ds_imerg[\"total_precipitation_24hr\"])\n",
    "    img_pt = _nearest_on_grid(img, lat, lon)\n",
    "\n",
    "    st_s  = _time_slice(st,     y0, m0, y1, m1)\n",
    "    img_s = _time_slice(img_pt, y0, m0, y1, m1)\n",
    "    if st_s.sizes.get(\"time\",0)==0 or img_s.sizes.get(\"time\",0)==0:\n",
    "        print(\"‚ö†Ô∏è No data in requested window.\"); return\n",
    "\n",
    "    series, ylab = _wbx_series(img_s, st_s, metric)\n",
    "\n",
    "    if doy_cb_img.value:\n",
    "        s = _to_doy_mean(series)\n",
    "        fig, ax = plt.subplots(figsize=(10,4))\n",
    "        s.plot(ax=ax, x=\"DOY\", label=\"IMERG vs Station\")\n",
    "        _month_ticks_for_doy(ax); ax.set_xlabel(\"month\")\n",
    "    else:\n",
    "        s = _to_monthly(series, \"time\")\n",
    "        fig, ax = plt.subplots(figsize=(10,4))\n",
    "        s.plot(ax=ax, x=\"time\", label=\"IMERG vs Station\")\n",
    "\n",
    "    ax.set_ylabel(f\"{ylab} (mm/day)\")\n",
    "    period_txt = f\"{y0}-{y1} ({m0:02d}‚Üí{m1:02d})\"\n",
    "    ax.set_title(f\"{metric} ‚Äî PRECIP ‚Äî Station vs IMERG ‚Äî {period_txt}\")\n",
    "    ax.grid(True, alpha=0.3); ax.legend(); plt.show()\n",
    "\n",
    "run_btn_img.on_click(_run_img)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIFS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
