{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb0fe644",
   "metadata": {},
   "source": [
    "\n",
    "# üåç Demo 5: Ground Truth Challenge \n",
    "\n",
    "\n",
    "## üß† Learning Objectives\n",
    "- Use ML metrics to understand how ground truth datasets differ from one another.\n",
    "- We will use the provided data as ground truth and comparing against popular global datasets that are used for training AI models\n",
    "- Load your ground truth data (*or any dataset in NC/Zarr*) and compare to **ERA5** and **IMERG** datasets.\n",
    "- Compute metrics to understand overall and spatial bias over the entire extent of the data. \n",
    "- Focus evaluation on specific regions relevant to the ground truth data.\n",
    "- Visualize differences between ground truth and global datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e77cf18",
   "metadata": {},
   "source": [
    "\n",
    "## üì¶ Environment Requirements\n",
    "If the environment is not already selected, select the `benchmarks_env` when prompted to activate the environment after the first cell is run. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774c18d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from IPython.display import display, Markdown\n",
    "plt.rcParams.update({\"figure.dpi\": 140})\n",
    "xr.set_options(keep_attrs=True)\n",
    "from weatherbenchX.metrics import deterministic\n",
    "from weatherbenchX.metrics import base as metrics_base\n",
    "\n",
    "plt.rcParams.update({\"figure.dpi\": 120})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdb193a",
   "metadata": {},
   "outputs": [],
   "source": [
    "VAR = \"total_precipitation_24hr\"\n",
    "\n",
    "REGIONS = {\n",
    "    \"Global\":     {\"latitude\": slice( 90, -90), \"longitude\": slice(  0, 360)},\n",
    "    \"Ethiopia\":   {\"latitude\": slice(14.9,  3.4), \"longitude\": slice(33.0, 48.0)},\n",
    "    \"Nigeria\":    {\"latitude\": slice(14.7,  4.0), \"longitude\": slice( 2.7, 14.7)},\n",
    "    \"Kenya\":      {\"latitude\": slice( 5.0, -4.7), \"longitude\": slice(33.9, 41.9)},\n",
    "    \"Bangladesh\": {\"latitude\": slice(26.7, 20.7), \"longitude\": slice(88.0, 92.7)},\n",
    "    \"Chile\":      {\"latitude\": slice(-17.5,-56.0), \"longitude\": slice(284.0, 294.0)},\n",
    "}\n",
    "\n",
    "\n",
    "IMD_PRECIP_DEFAULT   = \"gs://aim4scale_training_25/ground_truth/IMD_rainfall_0p25.zarr\"\n",
    "IMD_MASK_DEFAULT     = \"IMD_mask.nc\"  # your ocean/coverage mask file\n",
    "BMD_DAILY_DEFAULT    = \"gs://aim4scale_training_25/ground_truth/BMD_daily_combined_0p25.zarr\"\n",
    "IMERG_PRECIP_DEFAULT = \"gs://aim4scale_training_25/ground_truth/IMERG_0p25_2000_2025.zarr\"\n",
    "ERA5_PRECIP_DEFAULT  = \"gs://aim4scale_training_25/ground_truth/era5_24hr.zarr\"\n",
    "ERA5_TEMP_DEFAULT    = \"gs://aim4scale_training_25/ground_truth/era5_t2m_1D_1981_2024.zarr\"\n",
    "\n",
    "# Widgets\n",
    "p_imd   = widgets.Text(value=IMD_PRECIP_DEFAULT,   description=\"IMD precip:\",   layout=widgets.Layout(width=\"95%\"))\n",
    "p_imdmsk= widgets.Text(value=IMD_MASK_DEFAULT,     description=\"IMD mask:\",     layout=widgets.Layout(width=\"95%\"))\n",
    "p_bmd   = widgets.Text(value=BMD_DAILY_DEFAULT,    description=\"BMD daily:\",    layout=widgets.Layout(width=\"95%\"))\n",
    "p_imerg = widgets.Text(value=IMERG_PRECIP_DEFAULT, description=\"IMERG precip:\", layout=widgets.Layout(width=\"95%\"))\n",
    "p_e5_p  = widgets.Text(value=ERA5_PRECIP_DEFAULT,  description=\"ERA5 precip:\",  layout=widgets.Layout(width=\"95%\"))\n",
    "p_e5_t  = widgets.Text(value=ERA5_TEMP_DEFAULT,    description=\"ERA5 temp:\",    layout=widgets.Layout(width=\"95%\"))\n",
    "\n",
    "btn_load = widgets.Button(description=\"Load datasets\", button_style=\"primary\")\n",
    "load_out = widgets.Output()\n",
    "\n",
    "display(p_imd, p_imdmsk, p_bmd, p_imerg, p_e5_p, p_e5_t, btn_load, load_out)\n",
    "\n",
    "def _open_any(path: str):\n",
    "    if not path:\n",
    "        raise ValueError(\"Empty path.\")\n",
    "    return xr.open_zarr(path) if path.endswith(\".zarr\") else xr.open_dataset(path)\n",
    "\n",
    "ds_imd = ds_imd_mask = ds_bmd = ds_imerg = ds_e5_p = ds_e5_t = None\n",
    "\n",
    "def _summ(ds):\n",
    "    vs = list(ds.data_vars)[:6]\n",
    "    tcoord = \"time\" if \"time\" in ds.coords else (\"valid_time\" if \"valid_time\" in ds.coords else None)\n",
    "    if tcoord:\n",
    "        tmin = pd.to_datetime(str(ds[tcoord].min().values)).date()\n",
    "        tmax = pd.to_datetime(str(ds[tcoord].max().values)).date()\n",
    "        ttxt = f\"{tmin} ‚Ä¶ {tmax}\"\n",
    "    else:\n",
    "        ttxt = \"‚Äî\"\n",
    "    return f\"vars: {vs} | sizes: {dict(ds.sizes)} | time: {ttxt}\"\n",
    "\n",
    "def _load_all(_):\n",
    "    global ds_imd, ds_imd_mask, ds_bmd, ds_imerg, ds_e5_p, ds_e5_t\n",
    "    with load_out:\n",
    "        load_out.clear_output()\n",
    "        try:\n",
    "            ds_imd      = _open_any(p_imd.value.strip())\n",
    "            ds_imd_mask = _open_any(p_imdmsk.value.strip())  # NetCDF with NaN over ocean\n",
    "            ds_bmd      = _open_any(p_bmd.value.strip())\n",
    "            ds_imerg    = _open_any(p_imerg.value.strip())\n",
    "            ds_e5_p     = _open_any(p_e5_p.value.strip())\n",
    "            ds_e5_t     = _open_any(p_e5_t.value.strip())\n",
    "            display(Markdown(\"### ‚úÖ Loaded\"))\n",
    "            for name, ds in [(\"IMD\", ds_imd), (\"IMD mask\", ds_imd_mask), (\"BMD\", ds_bmd),\n",
    "                             (\"IMERG\", ds_imerg), (\"ERA5 precip\", ds_e5_p), (\"ERA5 temp\", ds_e5_t)]:\n",
    "                display(Markdown(f\"- **{name}** ‚Üí `{_summ(ds)}`\"))\n",
    "        except Exception as e:\n",
    "            display(Markdown(f\"‚ùå Load error: `{e}`\"))\n",
    "\n",
    "btn_load.on_click(_load_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b403dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _open_any(path: str):\n",
    "    return xr.open_zarr(path) if path.endswith(\".zarr\") else xr.open_dataset(path)\n",
    "\n",
    "def _to_0360(obj):\n",
    "    if \"longitude\" in obj.coords:\n",
    "        lon = obj[\"longitude\"]\n",
    "        try:\n",
    "            if float(lon.min()) < 0:\n",
    "                obj = obj.assign_coords(longitude=(lon % 360))\n",
    "        except Exception:\n",
    "            pass\n",
    "        obj = obj.sortby(\"longitude\")\n",
    "    return obj\n",
    "\n",
    "def _ensure_lat_ascending(obj):\n",
    "    if \"latitude\" in obj.coords:\n",
    "        lat = obj[\"latitude\"].values\n",
    "        if len(lat) > 1 and lat[0] > lat[-1]:\n",
    "            obj = obj.sortby(\"latitude\")\n",
    "    return obj\n",
    "\n",
    "def _region_to_0360(region):\n",
    "    a = float(region[\"longitude\"].start); b = float(region[\"longitude\"].stop)\n",
    "    return {\n",
    "        \"latitude\":  slice(region[\"latitude\"].start, region[\"latitude\"].stop),\n",
    "        \"longitude\": slice(a % 360, b % 360),\n",
    "    }\n",
    "\n",
    "def _apply_region_safe(ds, region):\n",
    "    ds1 = _ensure_lat_ascending(_to_0360(ds))\n",
    "    r0360 = _region_to_0360(region)\n",
    "    lo = min(r0360[\"longitude\"].start, r0360[\"longitude\"].stop)\n",
    "    hi = max(r0360[\"longitude\"].start, r0360[\"longitude\"].stop)\n",
    "    lat_lo = min(region[\"latitude\"].start, region[\"latitude\"].stop)\n",
    "    lat_hi = max(region[\"latitude\"].start, region[\"latitude\"].stop)\n",
    "    return ds1.sel(latitude=slice(lat_lo, lat_hi), longitude=slice(lo, hi))\n",
    "\n",
    "def _normalize_precip_units(da):\n",
    "    \"\"\"Unify precip to mm/day.\"\"\"\n",
    "    units = (da.attrs.get(\"units\") or da.attrs.get(\"unit\") or \"\").lower()\n",
    "    out = da\n",
    "    if units in [\"m\", \"meter\", \"metre\", \"m of water equivalent\"]:\n",
    "        out = out * 1000.0\n",
    "        out.attrs[\"units\"] = \"mm\"\n",
    "    elif units in [\"kg m-2\", \"kg/m^2\", \"kg m**-2\", \"mm\"]:\n",
    "        out.attrs[\"units\"] = \"mm\"  # 1 kg m-2 ‚âà 1 mm\n",
    "    else:\n",
    "        out.attrs[\"units\"] = \"mm\"  # assume mm if missing\n",
    "    return out\n",
    "\n",
    "def _coerce_valid_time(da):\n",
    "    \"\"\"Use valid_time for WBX.\"\"\"\n",
    "    if \"valid_time\" in da.dims:\n",
    "        return da\n",
    "    if \"time\" in da.dims:\n",
    "        return da.rename({\"time\": \"valid_time\"})\n",
    "    # try CF decode\n",
    "    try:\n",
    "        dec = xr.decode_cf(da.to_dataset(name=\"_tmp\")).to_array(\"_tmp\")\n",
    "        if \"time\" in dec.dims:\n",
    "            return dec.rename({\"time\": \"valid_time\"})\n",
    "    except Exception:\n",
    "        pass\n",
    "    raise ValueError(\"No recognizable time/valid_time dimension in array.\")\n",
    "\n",
    "def _time_intersect(a: xr.DataArray, b: xr.DataArray):\n",
    "    tmin = max(np.datetime64(a.valid_time.min().values), np.datetime64(b.valid_time.min().values))\n",
    "    tmax = min(np.datetime64(a.valid_time.max().values), np.datetime64(b.valid_time.max().values))\n",
    "    if tmax < tmin:\n",
    "        return a.isel(valid_time=slice(0,0)), b.isel(valid_time=slice(0,0))\n",
    "    return a.sel(valid_time=slice(tmin, tmax)), b.sel(valid_time=slice(tmin, tmax))\n",
    "\n",
    "def _prep_for_wbx(da: xr.DataArray):\n",
    "    \"\"\"WBX expects valid_time or init/lead_time; we give valid_time + lead_time=0.\"\"\"\n",
    "    if \"time\" in da.dims:\n",
    "        da = da.rename({\"time\": \"valid_time\"})\n",
    "    if \"valid_time\" not in da.dims:\n",
    "        raise ValueError(\"Need 'time' or 'valid_time' dimension.\")\n",
    "    return da.expand_dims({\"lead_time\": [np.timedelta64(0, \"h\")]})\n",
    "\n",
    "def _align_to_reference_grid(src: xr.DataArray, ref: xr.DataArray):\n",
    "    \"\"\"Put src on the label grid of ref. Try safe reindex before interp.\"\"\"\n",
    "    if \"latitude\" not in src.coords or \"longitude\" not in src.coords:\n",
    "        return src\n",
    "    s = _ensure_lat_ascending(_to_0360(src))\n",
    "    r = _ensure_lat_ascending(_to_0360(ref))\n",
    "    # fast path: identical\n",
    "    try:\n",
    "        if np.array_equal(s.latitude.values, r.latitude.values) and np.array_equal(s.longitude.values, r.longitude.values):\n",
    "            return s\n",
    "    except Exception:\n",
    "        pass\n",
    "    # reindex with small tolerance\n",
    "    try:\n",
    "        return s.reindex_like(r, method=\"nearest\", tolerance={\"latitude\":0.125, \"longitude\":0.125})\n",
    "    except Exception:\n",
    "        pass\n",
    "    # fallback: interp\n",
    "    return s.interp(latitude=r[\"latitude\"], longitude=r[\"longitude\"], method=\"nearest\")\n",
    "\n",
    "def _crop_to_imd_coverage(imd_valid: xr.DataArray):\n",
    "    \"\"\"\n",
    "    Keep only grid cells where IMD has any finite value in the selected window.\n",
    "    Avoid boolean dask indexers by converting to integer indices.\n",
    "    \"\"\"\n",
    "    spatial_mask = xr.ufuncs.isfinite(imd_valid).any(\"valid_time\")\n",
    "    lat_sel = spatial_mask.any(\"longitude\").compute().values  # numpy bool\n",
    "    lon_sel = spatial_mask.any(\"latitude\").compute().values   # numpy bool\n",
    "    lat_idx = np.where(lat_sel)[0]\n",
    "    lon_idx = np.where(lon_sel)[0]\n",
    "    if lat_idx.size == 0 or lon_idx.size == 0:\n",
    "        return (imd_valid.isel(valid_time=slice(0,0)), \n",
    "                imd_valid.latitude.isel(latitude=[]), \n",
    "                imd_valid.longitude.isel(longitude=[]))\n",
    "    imd_crop = imd_valid.isel(latitude=lat_idx, longitude=lon_idx)\n",
    "    return imd_crop, imd_valid.latitude.isel(latitude=lat_idx), imd_valid.longitude.isel(longitude=lon_idx)\n",
    "\n",
    "def _series_from_stats(stats, var, metric_name, spatial_dims=(\"latitude\",\"longitude\")):\n",
    "    if metric_name == \"RMSE\":\n",
    "        se = stats[\"SquaredError\"][var]\n",
    "        series = np.sqrt(se).mean(dim=[d for d in spatial_dims if d in se.dims], skipna=True).squeeze()\n",
    "        ylabel = \"RMSE (mm/day)\"\n",
    "    else:  # MAE\n",
    "        ae = stats[\"AbsoluteError\"][var]\n",
    "        series = ae.mean(dim=[d for d in spatial_dims if d in ae.dims], skipna=True).squeeze()\n",
    "        ylabel = \"MAE (mm/day)\"\n",
    "    # drop the dummy lead_time\n",
    "    if \"lead_time\" in series.dims and series.sizes.get(\"lead_time\", 1) == 1:\n",
    "        series = series.isel(lead_time=0)\n",
    "    # x-dim\n",
    "    xdim = \"valid_time\" if \"valid_time\" in series.dims else \"time\"\n",
    "    series = series.dropna(dim=xdim)\n",
    "    return series, ylabel, xdim\n",
    "\n",
    "def _summ(ds):\n",
    "    vs = \", \".join(list(ds.data_vars)[:6])\n",
    "    return f\"vars: {vs} | sizes: {dict(ds.sizes)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74612fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ERA5 precip\n",
    "if \"ds_e5_p\" not in globals():\n",
    "    if \"ds_era5_tp\" in globals() and ds_era5_tp is not None:\n",
    "        ds_e5_p = ds_era5_tp\n",
    "    elif \"ds_era5\" in globals() and ds_era5 is not None and \"total_precipitation_24hr\" in ds_era5:\n",
    "        ds_e5_p = ds_era5\n",
    "    elif \"ds_e5\" in globals() and ds_e5 is not None and \"total_precipitation_24hr\" in ds_e5:\n",
    "        ds_e5_p = ds_e5\n",
    "\n",
    "# ERA5 temperature (daily tavg/tmax)\n",
    "if \"ds_e5_t\" not in globals():\n",
    "    if \"ds_era5_t2m\" in globals() and ds_era5_t2m is not None:\n",
    "        ds_e5_t = ds_era5_t2m\n",
    "    elif \"ds_era5\" in globals() and ds_era5 is not None and (\"tavg\" in ds_era5 or \"tmax\" in ds_era5):\n",
    "        ds_e5_t = ds_era5\n",
    "\n",
    "# IMERG / IMD / BMD: leave as-is, but create shims if your loader used other names\n",
    "if \"ds_imerg\" not in globals() and \"ds_imerG\" in globals():\n",
    "    ds_imerg = ds_imerG\n",
    "if \"ds_imd\" not in globals() and \"ds_IMD\" in globals():\n",
    "    ds_imd = ds_IMD\n",
    "if \"ds_bmd\" not in globals() and \"ds_BMD\" in globals():\n",
    "    ds_bmd = ds_BMD\n",
    "\n",
    "# define the precip var name once (used in several cells)\n",
    "if \"VAR\" not in globals():\n",
    "    VAR = \"total_precipitation_24hr\"\n",
    "def _apply_region_safe(ds: xr.Dataset, region: dict) -> xr.Dataset:\n",
    "    \"\"\"\n",
    "    Slice safely even if lon systems differ. We convert DATA to 0..360, ensure\n",
    "    latitude ascending, and then slice. If the requested longitude range spans\n",
    "    the full globe (e.g., 0..360 or -180..180 modulo 360), we DO NOT slice lon.\n",
    "    \"\"\"\n",
    "    # normalize dataset to 0..360 & sorted coords\n",
    "    out = _ensure_lat_ascending(_to_0360(ds))\n",
    "\n",
    "    # latitude slice (always safe)\n",
    "    lat_a = float(region[\"latitude\"].start)\n",
    "    lat_b = float(region[\"latitude\"].stop)\n",
    "    lat_lo, lat_hi = (min(lat_a, lat_b), max(lat_a, lat_b))\n",
    "    if \"latitude\" in out.coords:\n",
    "        out = out.sel(latitude=slice(lat_lo, lat_hi))\n",
    "\n",
    "    # longitude slice ‚Äî detect full-globe requests\n",
    "    if \"longitude\" not in out.coords:\n",
    "        return out\n",
    "\n",
    "    lon_a = float(region[\"longitude\"].start)\n",
    "    lon_b = float(region[\"longitude\"].stop)\n",
    "\n",
    "    # convert requested bounds to 0..360\n",
    "    lon_a0360 = lon_a % 360.0\n",
    "    lon_b0360 = lon_b % 360.0\n",
    "    span = (lon_b0360 - lon_a0360) % 360.0\n",
    "\n",
    "    # If span == 0, user asked for full globe (e.g. 0..360 or -180..180) ‚Üí no lon slice\n",
    "    if np.isclose(span, 0.0):\n",
    "        return out\n",
    "\n",
    "    # Otherwise slice between lo/hi in 0..360 (no wrap crossing in our region set)\n",
    "    lon_lo, lon_hi = (min(lon_a0360, lon_b0360), max(lon_a0360, lon_b0360))\n",
    "    return out.sel(longitude=slice(lon_lo, lon_hi))\n",
    "\n",
    "def _coerce_valid_time(da: xr.DataArray) -> xr.DataArray:\n",
    "    if \"valid_time\" in da.dims:\n",
    "        return da\n",
    "    if \"time\" in da.dims:\n",
    "        return da.rename({\"time\": \"valid_time\"})\n",
    "    # last-resort CF decode\n",
    "    try:\n",
    "        dec = xr.decode_cf(da.to_dataset(name=\"_tmp\")).to_array(\"_tmp\")\n",
    "        if \"time\" in dec.dims:\n",
    "            return dec.rename({\"time\":\"valid_time\"})\n",
    "    except Exception:\n",
    "        pass\n",
    "    return da  # don't crash; caller will fail if truly missing\n",
    "\n",
    "if \"_prep_for_wbx_validtime\" not in globals():\n",
    "    def _prep_for_wbx_validtime(da: xr.DataArray) -> xr.DataArray:\n",
    "        da = _coerce_valid_time(da)\n",
    "        want = [\"valid_time\"] + [d for d in (\"latitude\",\"longitude\") if d in da.dims]\n",
    "        da = da.transpose(*want)\n",
    "        return da.expand_dims({\"lead_time\": [np.timedelta64(0, \"h\")]})\n",
    "\n",
    "if \"_prep_for_wbx_initlead\" not in globals():\n",
    "    def _prep_for_wbx_initlead(da: xr.DataArray) -> xr.DataArray:\n",
    "        da = _coerce_valid_time(da).rename({\"valid_time\":\"init_time\"})\n",
    "        want = [\"init_time\"] + [d for d in (\"latitude\",\"longitude\") if d in da.dims]\n",
    "        da = da.transpose(*want)\n",
    "        return da.expand_dims({\"lead_time\": [np.timedelta64(0, \"h\")]})\n",
    "\n",
    "# Optional: if your cells call _wbx_series(pred_ds, truth_ds, \"RMSE\"/\"MAE\") with Datasets,\n",
    "# wrap them here too (uses the two helpers above).\n",
    "try:\n",
    "    ds_imd_mask\n",
    "except NameError:\n",
    "    try:\n",
    "        IMD_MASK_PATH = \"IMD_mask.nc\"  # change if your file lives elsewhere\n",
    "        ds_imd_mask = xr.open_dataset(IMD_MASK_PATH)\n",
    "        display(Markdown(\"‚úÖ **Loaded IMD mask** (oceans/out-of-coverage are NaN)\"))\n",
    "    except Exception as e:\n",
    "        ds_imd_mask = None\n",
    "        display(Markdown(f\"‚ö†Ô∏è Could not load IMD mask: `{e}` ‚Äî maps will fall back to truth-coverage mask.\"))\n",
    "if \"_wbx_series\" not in globals():\n",
    "    from weatherbenchX.metrics import deterministic\n",
    "    from weatherbenchX.metrics import base as metrics_base\n",
    "\n",
    "    def _wbx_series(pred: xr.DataArray, truth: xr.DataArray, metric: str):\n",
    "        ds_p = xr.Dataset({\"var\": _prep_for_wbx_validtime(pred.astype(\"float32\"))})\n",
    "        ds_t = xr.Dataset({\"var\": _prep_for_wbx_validtime(truth.astype(\"float32\"))})\n",
    "        if metric.upper() == \"RMSE\":\n",
    "            stats = metrics_base.compute_unique_statistics_for_all_metrics({\"rmse\": deterministic.RMSE()}, ds_p, ds_t)\n",
    "            se = list(stats[\"SquaredError\"].values())[0]\n",
    "            series = (se ** 0.5).mean([d for d in (\"latitude\",\"longitude\") if d in se.dims], skipna=True)\n",
    "            ylabel = \"RMSE\"\n",
    "        else:\n",
    "            stats = metrics_base.compute_unique_statistics_for_all_metrics({\"mae\": deterministic.MAE()}, ds_p, ds_t)\n",
    "            ae = list(stats[\"AbsoluteError\"].values())[0]\n",
    "            series = ae.mean([d for d in (\"latitude\",\"longitude\") if d in ae.dims], skipna=True)\n",
    "            ylabel = \"MAE\"\n",
    "        if \"lead_time\" in series.dims and series.sizes.get(\"lead_time\",1) == 1:\n",
    "            series = series.isel(lead_time=0)\n",
    "        return series.rename({\"valid_time\":\"date\"}).squeeze(), ylabel\n",
    "# Cell 3 ‚Äî Helpers (units, grid, time, masking, WBX packers)\n",
    "\n",
    "VAR_P = \"total_precipitation_24hr\"\n",
    "\n",
    "def _to_0360(obj):\n",
    "    if \"longitude\" in obj.coords:\n",
    "        lon = obj[\"longitude\"]\n",
    "        try:\n",
    "            if float(lon.min()) < 0:\n",
    "                obj = obj.assign_coords(longitude=(lon % 360))\n",
    "        except Exception:\n",
    "            pass\n",
    "        obj = obj.sortby(\"longitude\")\n",
    "    return obj\n",
    "\n",
    "def _ensure_lat_asc(obj):\n",
    "    if \"latitude\" in obj.coords:\n",
    "        lat = obj[\"latitude\"].values\n",
    "        if len(lat) > 1 and lat[0] > lat[-1]:\n",
    "            obj = obj.sortby(\"latitude\")\n",
    "    return obj\n",
    "\n",
    "def _normalize_precip(da):\n",
    "    u = (da.attrs.get(\"units\") or da.attrs.get(\"unit\") or \"\").lower()\n",
    "    if u in [\"m\",\"meter\",\"metre\",\"m of water equivalent\"]:\n",
    "        da = da * 1000.0\n",
    "    da.attrs[\"units\"] = \"mm/day\"\n",
    "    return da\n",
    "\n",
    "def _normalize_temp(da):\n",
    "    u = (da.attrs.get(\"units\") or da.attrs.get(\"unit\") or \"\").lower()\n",
    "    if u in [\"k\",\"kelvin\"]:\n",
    "        da = da - 273.15\n",
    "    da.attrs[\"units\"] = \"¬∞C\"\n",
    "    return da\n",
    "\n",
    "def _coerce_time(da):\n",
    "    if \"time\" in da.dims:\n",
    "        return da\n",
    "    if \"valid_time\" in da.dims:\n",
    "        return da.rename({\"valid_time\":\"time\"})\n",
    "    try:\n",
    "        dec = xr.decode_cf(da.to_dataset(name=\"_tmp\")).to_array(\"_tmp\")\n",
    "        if \"time\" in dec.dims:\n",
    "            return dec\n",
    "    except Exception:\n",
    "        pass\n",
    "    return da\n",
    "\n",
    "def _align_to_truth_grid(src: xr.DataArray, truth: xr.DataArray) -> xr.DataArray:\n",
    "    s = _ensure_lat_asc(_to_0360(src))\n",
    "    t = _ensure_lat_asc(_to_0360(truth))\n",
    "    try:\n",
    "        if np.array_equal(s.latitude.values, t.latitude.values) and np.array_equal(s.longitude.values, t.longitude.values):\n",
    "            return s\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        return s.reindex_like(t, method=\"nearest\", tolerance={\"latitude\":0.125, \"longitude\":0.125})\n",
    "    except Exception:\n",
    "        pass\n",
    "    s2 = s.sortby([\"latitude\",\"longitude\"]); t2 = t.sortby([\"latitude\",\"longitude\"])\n",
    "    return s2.interp(latitude=t2[\"latitude\"], longitude=t2[\"longitude\"], method=\"nearest\")\n",
    "\n",
    "def _truth_land_mask(truth_da: xr.DataArray) -> xr.DataArray:\n",
    "    \"\"\"Mask (True) where truth has any finite value in the window.\"\"\"\n",
    "    return xr.ufuncs.isfinite(truth_da).any(\"time\")\n",
    "\n",
    "def _apply_imd_mask(imd_da: xr.DataArray, mask_ds: xr.Dataset | None) -> xr.DataArray:\n",
    "    \"\"\"Apply your IMD ocean mask (NaNs). Falls back to finite-any if mask missing.\"\"\"\n",
    "    if mask_ds is None:\n",
    "        return imd_da\n",
    "    # pick a variable from the mask file\n",
    "    if VAR_P in mask_ds.data_vars:\n",
    "        m = mask_ds[VAR_P]\n",
    "    else:\n",
    "        m = next(iter(mask_ds.data_vars.values()))\n",
    "    m = _ensure_lat_asc(_to_0360(_coerce_time(m)))\n",
    "    imd_da = _ensure_lat_asc(_to_0360(_coerce_time(imd_da)))\n",
    "    # align mask to IMD grid\n",
    "    try:\n",
    "        m_on = _align_to_truth_grid(m.isel(time=0) if \"time\" in m.dims else m, imd_da.isel(time=0))\n",
    "    except Exception:\n",
    "        m_on = m\n",
    "    return imd_da.where(~xr.ufuncs.isnan(m_on))\n",
    "\n",
    "# --- WeatherBenchX series packers (valid_time + lead_time=0) ---\n",
    "def _wbx_series(pred: xr.DataArray, truth: xr.DataArray, metric: str):\n",
    "    def _pack(da):\n",
    "        da = _coerce_time(da).rename({\"time\":\"valid_time\"})\n",
    "        want = [\"valid_time\"] + [d for d in (\"latitude\",\"longitude\") if d in da.dims]\n",
    "        da = da.transpose(*want)\n",
    "        return da.expand_dims({\"lead_time\":[np.timedelta64(0,\"h\")]})\n",
    "    ds_p = xr.Dataset({\"var\": _pack(pred.astype(\"float32\"))})\n",
    "    ds_t = xr.Dataset({\"var\": _pack(truth.astype(\"float32\"))})\n",
    "\n",
    "    if metric.upper() == \"RMSE\":\n",
    "        stats = metrics_base.compute_unique_statistics_for_all_metrics({\"rmse\": deterministic.RMSE()}, ds_p, ds_t)\n",
    "        se = list(stats[\"SquaredError\"].values())[0]\n",
    "        s = (se**0.5).mean([d for d in (\"latitude\",\"longitude\") if d in se.dims], skipna=True)\n",
    "        if \"lead_time\" in s.dims and s.sizes.get(\"lead_time\",1)==1:\n",
    "            s = s.isel(lead_time=0)\n",
    "        return s.rename({\"valid_time\":\"date\"}).squeeze(), \"RMSE\"\n",
    "    else:\n",
    "        stats = metrics_base.compute_unique_statistics_for_all_metrics({\"mae\": deterministic.MAE()}, ds_p, ds_t)\n",
    "        ae = list(stats[\"AbsoluteError\"].values())[0]\n",
    "        s = ae.mean([d for d in (\"latitude\",\"longitude\") if d in ae.dims], skipna=True)\n",
    "        if \"lead_time\" in s.dims and s.sizes.get(\"lead_time\",1)==1:\n",
    "            s = s.isel(lead_time=0)\n",
    "        return s.rename({\"valid_time\":\"date\"}).squeeze(), \"MAE\"\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cdd840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================================\n",
    "# BMD truth: RMSE/MAE/SEEPS (SEEPS for precip only)\n",
    "# - Uses WeatherBenchX\n",
    "# ===========================================================\n",
    "import numpy as np, pandas as pd, xarray as xr, matplotlib.pyplot as plt, ipywidgets as widgets\n",
    "from IPython.display import display, Markdown\n",
    "from weatherbenchX.metrics import deterministic\n",
    "from weatherbenchX.metrics import base as metrics_base\n",
    "from weatherbenchX.metrics.categorical import SEEPS as WBX_SEEPS\n",
    "\n",
    "plt.rcParams.update({\"figure.dpi\": 120})\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def _as_da(obj):\n",
    "    if isinstance(obj, xr.DataArray):\n",
    "        return obj\n",
    "    if isinstance(obj, xr.Dataset):\n",
    "        if not obj.data_vars:\n",
    "            raise ValueError(\"Empty Dataset where DataArray expected.\")\n",
    "        return obj[next(iter(obj.data_vars))]\n",
    "    raise TypeError(f\"Expected DataArray/Dataset, got {type(obj)}\")\n",
    "\n",
    "ALIASES = {\n",
    "    \"precip\": [\"total_precipitation_24hr\", \"tp_24h\", \"tp_daily\", \"precip\", \"rain\"],\n",
    "    \"tavg\":   [\"tavg\", \"t2m_mean\", \"t2m_daily_mean\", \"daily_mean_temperature\", \"tas_mean\", \"tmean\"],\n",
    "    \"tmax\":   [\"tmax\", \"t2m_max\",  \"t2m_daily_max\",  \"daily_max_temperature\", \"tasmax\",  \"tmax_mean\"],\n",
    "}\n",
    "LABEL  = {\"precip\": \"Precip (mm/day)\", \"tavg\": \"Temp avg (¬∞C)\", \"tmax\": \"Temp max (¬∞C)\"}\n",
    "\n",
    "def _first_present(ds, names):\n",
    "    if ds is None: return None\n",
    "    for n in names:\n",
    "        if n in ds.data_vars: return n\n",
    "    return None\n",
    "\n",
    "def _normalize_precip_units(da):\n",
    "    u = (da.attrs.get(\"units\") or da.attrs.get(\"unit\") or \"\").lower()\n",
    "    if u in [\"m\",\"meter\",\"metre\",\"m of water equivalent\"]:\n",
    "        da = da * 1000.0\n",
    "    da.attrs[\"units\"] = \"mm/day\"\n",
    "    return da\n",
    "\n",
    "def _normalize_temp_units_C(da):\n",
    "    u = (da.attrs.get(\"units\") or da.attrs.get(\"unit\") or \"\").lower()\n",
    "    if \"k\" in u and \"pa\" not in u:\n",
    "        da = da - 273.15\n",
    "    da.attrs[\"units\"] = \"¬∞C\"\n",
    "    return da\n",
    "\n",
    "def _norm_by_key(key, da):\n",
    "    return _normalize_precip_units(da) if key==\"precip\" else _normalize_temp_units_C(da)\n",
    "\n",
    "def _coerce_valid_time(da):\n",
    "    if \"valid_time\" in da.dims: return da\n",
    "    if \"time\" in da.dims:       return da.rename({\"time\":\"valid_time\"})\n",
    "    dec = xr.decode_cf(da.to_dataset(name=\"_tmp\"), use_cftime=False).to_array(\"_tmp\")\n",
    "    if \"time\" in dec.dims:      return dec.rename({\"time\":\"valid_time\"})\n",
    "    raise ValueError(\"No time/valid_time dimension found.\")\n",
    "\n",
    "def _to_0360(obj):\n",
    "    if \"longitude\" in obj.coords:\n",
    "        lon = obj[\"longitude\"]\n",
    "        try:\n",
    "            if float(lon.min()) < 0:\n",
    "                obj = obj.assign_coords(longitude=(lon % 360))\n",
    "        except Exception:\n",
    "            pass\n",
    "        obj = obj.sortby(\"longitude\")\n",
    "    return obj\n",
    "\n",
    "def _ensure_lat_asc(obj):\n",
    "    if \"latitude\" in obj.coords:\n",
    "        lat = obj[\"latitude\"].values\n",
    "        if len(lat) > 1 and lat[0] > lat[-1]:\n",
    "            obj = obj.sortby(\"latitude\")\n",
    "    return obj\n",
    "\n",
    "def _align_to_reference_grid(src: xr.DataArray, ref: xr.DataArray) -> xr.DataArray:\n",
    "    s = _ensure_lat_asc(_to_0360(src)); r = _ensure_lat_asc(_to_0360(ref))\n",
    "    try:\n",
    "        if np.array_equal(s.latitude.values, r.latitude.values) and np.array_equal(s.longitude.values, r.longitude.values):\n",
    "            return s\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        return s.reindex_like(r, method=\"nearest\", tolerance={\"latitude\":0.125,\"longitude\":0.125})\n",
    "    except Exception:\n",
    "        pass\n",
    "    s2 = s.sortby([\"latitude\",\"longitude\"]); r2 = r.sortby([\"latitude\",\"longitude\"])\n",
    "    return s2.interp(latitude=r2[\"latitude\"], longitude=r2[\"longitude\"], method=\"nearest\")\n",
    "\n",
    "def _prep_for_wbx_validtime(da: xr.DataArray) -> xr.DataArray:\n",
    "    da = _coerce_valid_time(da)\n",
    "    want = [\"valid_time\"] + [d for d in (\"latitude\",\"longitude\") if d in da.dims]\n",
    "    da = da.transpose(*want)\n",
    "    return da.expand_dims({\"lead_time\":[np.timedelta64(0,\"h\")]})\n",
    "\n",
    "def _prep_for_wbx_initlead(da: xr.DataArray) -> xr.DataArray:\n",
    "    da = _coerce_valid_time(da).rename({\"valid_time\":\"init_time\"})\n",
    "    want = [\"init_time\"] + [d for d in (\"latitude\",\"longitude\") if d in da.dims]\n",
    "    da = da.transpose(*want).expand_dims({\"lead_time\":[np.timedelta64(0,\"h\")]})\n",
    "    return da.transpose(\"lead_time\",\"init_time\",*(d for d in (\"latitude\",\"longitude\") if d in da.dims))\n",
    "\n",
    "def _wbx_series(pred_da: xr.DataArray, truth_da: xr.DataArray, metric_name: str):\n",
    "    pred_da  = _as_da(pred_da)\n",
    "    truth_da = _as_da(truth_da)\n",
    "    pred_ds  = xr.Dataset({\"var\": _prep_for_wbx_validtime(pred_da)})\n",
    "    truth_ds = xr.Dataset({\"var\": _prep_for_wbx_validtime(truth_da)})\n",
    "    metrics  = {\"rmse\": deterministic.RMSE()} if metric_name==\"RMSE\" else {\"mae\": deterministic.MAE()}\n",
    "    stats    = metrics_base.compute_unique_statistics_for_all_metrics(metrics, pred_ds, truth_ds)\n",
    "    if metric_name == \"RMSE\":\n",
    "        se = stats[\"SquaredError\"][\"var\"]\n",
    "        s  = (se**0.5).mean([d for d in (\"latitude\",\"longitude\") if d in se.dims], skipna=True)\n",
    "        ylab = \"mm/day\"\n",
    "    else:\n",
    "        ae = stats[\"AbsoluteError\"][\"var\"]\n",
    "        s  = ae.mean([d for d in (\"latitude\",\"longitude\") if d in ae.dims], skipna=True)\n",
    "        # unit label by variable type\n",
    "        ylab = \"mm/day\" if \"precip\" in str(truth_da.name).lower() else \"¬∞C\"\n",
    "    s = s.isel(lead_time=0).rename({\"valid_time\":\"date\"}).squeeze()\n",
    "    return s, ylab\n",
    "\n",
    "def _series_from_seeps(stats: dict):\n",
    "    key = [k for k in stats.keys() if k.startswith(\"SEEPS\") or k==\"SEEPS\"]\n",
    "    if not key: key = [list(stats.keys())[0]]\n",
    "    da = list(stats[key[0]].values())[0]\n",
    "    if \"lead_time\" in da.dims and da.sizes.get(\"lead_time\",1)==1:\n",
    "        da = da.isel(lead_time=0)\n",
    "    s = da.mean([d for d in (\"latitude\",\"longitude\") if d in da.dims], skipna=True)\n",
    "    xdim = \"init_time\" if \"init_time\" in s.dims else (\"valid_time\" if \"valid_time\" in s.dims else \"time\")\n",
    "    return s.squeeze().dropna(dim=xdim), xdim\n",
    "\n",
    "def _doy_mean(series: xr.DataArray, xdim_hint: str | None = None):\n",
    "    xdim = xdim_hint or (\"init_time\" if \"init_time\" in series.dims else \"valid_time\" if \"valid_time\" in series.dims else None)\n",
    "    if xdim is None or series.sizes.get(xdim, 0) == 0:\n",
    "        return series, (xdim_hint or \"time\")\n",
    "    s = series.groupby(f\"{xdim}.dayofyear\").mean(skipna=True)\n",
    "    s = s.rename({\"dayofyear\":\"DOY\"}).assign_coords(DOY=s[\"DOY\"].astype(int))\n",
    "    return s, \"DOY\"\n",
    "\n",
    "def _to_monthly(series: xr.DataArray, time_dim: str) -> xr.DataArray:\n",
    "    \"\"\"Aggregate a daily series to monthly means for plotting by month.\"\"\"\n",
    "    ts = pd.to_datetime(series[time_dim].values)\n",
    "    s2 = series.assign_coords({time_dim: ts}).resample({time_dim: \"MS\"}).mean(skipna=True)\n",
    "    return s2\n",
    "\n",
    "# ---------- inputs UI (unchanged) ----------\n",
    "BMD_PATH_DEFAULT     = \"gs://aim4scale_training_25/ground_truth/BMD_daily_combined_0p25.zarr\"\n",
    "ERA5_TP_PATH_DEFAULT = \"gs://aim4scale_training_25/ground_truth/era5_24hr.zarr\"\n",
    "ERA5_T2M_PATH_DEFAULT= \"gs://aim4scale_training_25/ground_truth/era5_t2m_1D_1981_2024.zarr\"\n",
    "IMERG_PATH_DEFAULT   = \"gs://aim4scale_training_25/ground_truth/IMERG_0p25_2000_2025.zarr\"\n",
    "\n",
    "bmd_txt   = widgets.Text(value=BMD_PATH_DEFAULT,     description=\"BMD:\",    layout=widgets.Layout(width=\"95%\"))\n",
    "era5p_txt = widgets.Text(value=ERA5_TP_PATH_DEFAULT, description=\"ERA5 tp:\",layout=widgets.Layout(width=\"95%\"))\n",
    "era5t_txt = widgets.Text(value=ERA5_T2M_PATH_DEFAULT,description=\"ERA5 t2m:\",layout=widgets.Layout(width=\"95%\"))\n",
    "imerg_txt = widgets.Text(value=IMERG_PATH_DEFAULT,   description=\"IMERG:\",  layout=widgets.Layout(width=\"95%\"))\n",
    "metric_dd = widgets.Dropdown(options=[\"RMSE\",\"MAE\",\"SEEPS\"], description=\"Metric:\", value=\"RMSE\")\n",
    "doy_avg_cb= widgets.Checkbox(value=False, description=\"Average by DOY (multi-year mean line)\")\n",
    "t0_txt    = widgets.Text(value=\"2018-06-01\", description=\"Start (YYYY-MM-DD):\")\n",
    "t1_txt    = widgets.Text(value=\"2019-06-30\", description=\"End   (YYYY-MM-DD):\")\n",
    "btn_run   = widgets.Button(description=\"Run (BMD truth, land-only)\", button_style=\"success\")\n",
    "out_all   = widgets.Output()\n",
    "display(bmd_txt, era5p_txt, era5t_txt, imerg_txt, metric_dd, doy_avg_cb, t0_txt, t1_txt, btn_run, out_all)\n",
    "\n",
    "# ---------- main ----------\n",
    "ds_bmd = ds_era5_tp = ds_era5_t2m = ds_imerg = None\n",
    "\n",
    "def _load(path):\n",
    "    p = path.strip()\n",
    "    if not p: return None\n",
    "    return xr.open_zarr(p) if p.endswith(\".zarr\") else xr.open_dataset(p)\n",
    "\n",
    "@out_all.capture(clear_output=True)\n",
    "def _run_all(_):\n",
    "    global ds_bmd, ds_era5_tp, ds_era5_t2m, ds_imerg\n",
    "    if ds_bmd      is None: ds_bmd      = _load(bmd_txt.value)\n",
    "    if ds_era5_tp  is None: ds_era5_tp  = _load(era5p_txt.value)\n",
    "    if ds_era5_t2m is None: ds_era5_t2m = _load(era5t_txt.value)\n",
    "    if ds_imerg    is None: ds_imerg    = _load(imerg_txt.value)\n",
    "\n",
    "    if ds_bmd is None:\n",
    "        print(\"‚ùå Need BMD.\"); return\n",
    "    if ds_era5_tp is None and ds_era5_t2m is None and ds_imerg is None:\n",
    "        print(\"‚ùå Need at least one predictor (ERA5 tp / ERA5 t2m / IMERG).\"); return\n",
    "\n",
    "    mapping = {}\n",
    "    for key, aliases in ALIASES.items():\n",
    "        mapping[key] = {\n",
    "            \"bmd\":   _first_present(ds_bmd, aliases),\n",
    "            \"era5\":  _first_present(ds_era5_tp if key==\"precip\" else ds_era5_t2m, aliases),\n",
    "            \"imerg\": _first_present(ds_imerg, aliases) if key==\"precip\" else None,\n",
    "            \"_era5_src\": \"tp\" if key==\"precip\" else \"t2m\",\n",
    "        }\n",
    "\n",
    "    keys = [k for k in [\"precip\",\"tavg\",\"tmax\"]\n",
    "            if mapping[k][\"bmd\"] and (mapping[k][\"era5\"] is not None or mapping[k][\"imerg\"] is not None)]\n",
    "    if not keys:\n",
    "        print(\"‚ùå No overlapping variables. Check variable names.\"); return\n",
    "\n",
    "    metric = metric_dd.value\n",
    "    t0 = np.datetime64(pd.to_datetime(t0_txt.value).normalize())\n",
    "    t1 = np.datetime64(pd.to_datetime(t1_txt.value).normalize())\n",
    "\n",
    "    display(Markdown(f\"**Running** {', '.join(LABEL[k] for k in keys)}  \\n\"\n",
    "                     f\"Metric: `{metric}` ‚Äî Window: `{str(t0)}` ‚Üí `{str(t1)}`  \\n\"\n",
    "                     f\"Mask: **BMD land/coverage (finite-any in window)**\"))\n",
    "\n",
    "    for key in keys:\n",
    "        vb = mapping[key][\"bmd\"]\n",
    "        ve = mapping[key][\"era5\"]\n",
    "        vi = mapping[key][\"imerg\"]\n",
    "        era5_src = mapping[key][\"_era5_src\"]\n",
    "        display(Markdown(f\"### {LABEL[key]}\"))\n",
    "\n",
    "        B = _norm_by_key(key, ds_bmd[vb]).sel(time=slice(t0, t1))\n",
    "        if B.sizes.get(\"time\",0)==0 and B.sizes.get(\"valid_time\",0)==0:\n",
    "            display(Markdown(\"‚ö†Ô∏è No BMD data in this window.\")); \n",
    "            continue\n",
    "        B = _coerce_valid_time(B)\n",
    "\n",
    "        preds = []\n",
    "        if ve is not None:\n",
    "            E = (_norm_by_key(key, (ds_era5_tp if era5_src==\"tp\" else ds_era5_t2m)[ve])\n",
    "                 .sel(time=slice(t0, t1)))\n",
    "            E = _coerce_valid_time(E)\n",
    "            preds.append((\"ERA5\", E))\n",
    "        if vi is not None:\n",
    "            I = _coerce_valid_time(_norm_by_key(key, ds_imerg[vi]).sel(time=slice(t0, t1)))\n",
    "            preds.append((\"IMERG\", I))\n",
    "\n",
    "        if not preds:\n",
    "            display(Markdown(\"‚ö†Ô∏è No predictor for this variable.\")); \n",
    "            continue\n",
    "\n",
    "        for label, P in preds:\n",
    "            P_on = _align_to_reference_grid(P, B)\n",
    "\n",
    "            tmin = max(np.datetime64(B.valid_time.min().values), np.datetime64(P_on.valid_time.min().values))\n",
    "            tmax = min(np.datetime64(B.valid_time.max().values), np.datetime64(P_on.valid_time.max().values))\n",
    "            if tmax < tmin:\n",
    "                print(f\"‚ö†Ô∏è No time overlap with {label}.\"); \n",
    "                continue\n",
    "            B_use = B.sel(valid_time=slice(tmin, tmax))\n",
    "            P_use = P_on.sel(valid_time=slice(tmin, tmax))\n",
    "\n",
    "            mask = xr.ufuncs.isfinite(B_use).any(dim=\"valid_time\")\n",
    "            B_mask = B_use.where(mask)\n",
    "            P_mask = P_use.where(mask)\n",
    "\n",
    "            if metric == \"SEEPS\" and key == \"precip\":\n",
    "                P_wbx = _prep_for_wbx_initlead(P_mask)\n",
    "                B_wbx = _prep_for_wbx_initlead(B_mask)\n",
    "\n",
    "                # Build SEEPS climatology from FULL BMD on the evaluation grid\n",
    "                full_bmd_all = _normalize_precip_units(_ensure_lat_asc(_to_0360(ds_bmd[vb])))\n",
    "                full_bmd_region = full_bmd_all.sel(latitude=B_mask.latitude, longitude=B_mask.longitude)\n",
    "\n",
    "                # build BOTH fields (threshold + dry_fraction)\n",
    "                dry_thr = 0.25\n",
    "                wet = full_bmd_region.where(full_bmd_region >= dry_thr)\n",
    "                thr = wet.groupby(\"time.dayofyear\").quantile(0.5, dim=\"time\", skipna=True)\n",
    "                if \"quantile\" in thr.dims: thr = thr.sel(quantile=0.5, drop=True)\n",
    "                dry = (full_bmd_region < dry_thr).groupby(\"time.dayofyear\").mean(\"time\", skipna=True)\n",
    "                all_doy = np.arange(1, 367, dtype=np.int16)\n",
    "                thr = thr.rename({d:\"dayofyear\" for d in thr.dims if d.endswith(\"dayofyear\")}).reindex(dayofyear=all_doy).fillna(dry_thr)\n",
    "                dry = dry.rename({d:\"dayofyear\" for d in dry.dims if d.endswith(\"dayofyear\")}).reindex(dayofyear=all_doy).fillna(0.0).clip(0,1)\n",
    "                hours = np.arange(24, dtype=np.int16)\n",
    "                thr = thr.expand_dims(hour=hours).astype(\"float32\").rename(\"total_precipitation_24hr_seeps_threshold\")\n",
    "                dry = dry.expand_dims(hour=hours).astype(\"float32\").rename(\"total_precipitation_24hr_seeps_dry_fraction\")\n",
    "                clim_ds = xr.Dataset({\"total_precipitation_24hr_seeps_threshold\": thr,\n",
    "                                      \"total_precipitation_24hr_seeps_dry_fraction\": dry})\n",
    "\n",
    "                seeps_metric = WBX_SEEPS(variables=[\"total_precipitation_24hr\"], climatology=clim_ds,\n",
    "                                         dry_threshold_mm=dry_thr, min_p1=0.10, max_p1=0.85)\n",
    "\n",
    "                stats = metrics_base.compute_unique_statistics_for_all_metrics(\n",
    "                    {\"seeps\": seeps_metric},\n",
    "                    xr.Dataset({\"total_precipitation_24hr\": P_wbx}),\n",
    "                    xr.Dataset({\"total_precipitation_24hr\": B_wbx})\n",
    "                )\n",
    "\n",
    "                series, xdim = _series_from_seeps(stats)\n",
    "                series = series.clip(min=0.0, max=1.0)\n",
    "\n",
    "                # monthly mean for plotting\n",
    "                series_m = _to_monthly(series, xdim)\n",
    "\n",
    "                fig, ax = plt.subplots(figsize=(9, 3.6))\n",
    "                series_m.plot(ax=ax, x=series_m.dims[0])\n",
    "                ax.set_title(f\"SEEPS ‚Äî {label} vs BMD ‚Äî total_precipitation_24hr (monthly)\")\n",
    "                ax.set_ylabel(\"SEEPS (0 best)\"); ax.grid(True, alpha=0.3); plt.show()\n",
    "\n",
    "                try:\n",
    "                    display(Markdown(f\"**Mean SEEPS over window ‚Äî {label}:** `{float(series_m.mean().values):.3f}`\"))\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "            else:\n",
    "                use_metric = metric if metric in (\"RMSE\",\"MAE\") else \"RMSE\"\n",
    "                if metric == \"SEEPS\" and key != \"precip\":\n",
    "                    print(\"‚ÑπÔ∏è SEEPS is precipitation-only; using RMSE for temperature.\")\n",
    "\n",
    "                series, ylab = _wbx_series(P_mask, B_mask, use_metric)\n",
    "                # monthly mean\n",
    "                series_m = _to_monthly(series, \"date\")\n",
    "\n",
    "                fig, ax = plt.subplots(figsize=(9, 3.6))\n",
    "                series_m.plot(ax=ax, x=\"date\")\n",
    "                ax.set_title(f\"{use_metric} ‚Äî {label} vs BMD ‚Äî {(vb if key!='precip' else 'total_precipitation_24hr')} (monthly)\")\n",
    "                ax.set_ylabel(ylab); ax.set_xlabel(\"month\"); ax.grid(True, alpha=0.3)\n",
    "                plt.show()\n",
    "\n",
    "                try:\n",
    "                    mval = float(series_m.mean().values)\n",
    "                    display(Markdown(f\"**Mean {use_metric} over window ‚Äî {label}:** `{mval:.3f} {ylab}`\"))\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "btn_run.on_click(_run_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6e44c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3 ‚Äî Helpers (units, grids, time, masking, WBX series)\n",
    "\n",
    "VAR_P = \"total_precipitation_24hr\"\n",
    "\n",
    "def _to_0360(obj):\n",
    "    if \"longitude\" in obj.coords:\n",
    "        lon = obj[\"longitude\"]\n",
    "        try:\n",
    "            if float(lon.min()) < 0:\n",
    "                obj = obj.assign_coords(longitude=(lon % 360))\n",
    "        except Exception:\n",
    "            pass\n",
    "        obj = obj.sortby(\"longitude\")\n",
    "    return obj\n",
    "\n",
    "def _ensure_lat_asc(obj):\n",
    "    for latn in (\"latitude\",\"lat\"):\n",
    "        if latn in obj.coords:\n",
    "            lat = obj[latn].values\n",
    "            if len(lat) > 1 and lat[0] > lat[-1]:\n",
    "                obj = obj.sortby(latn)\n",
    "    return obj\n",
    "\n",
    "def _normalize_precip(da):\n",
    "    u = (da.attrs.get(\"units\") or da.attrs.get(\"unit\") or \"\").lower()\n",
    "    out = da\n",
    "    if u in [\"m\",\"meter\",\"metre\",\"m of water equivalent\"]:\n",
    "        out = out * 1000.0\n",
    "    out.attrs[\"units\"] = \"mm/day\"\n",
    "    return out\n",
    "\n",
    "def _normalize_temp(da):\n",
    "    u = (da.attrs.get(\"units\") or da.attrs.get(\"unit\") or \"\").lower()\n",
    "    out = da\n",
    "    if u in [\"k\",\"kelvin\"]:\n",
    "        out = out - 273.15\n",
    "    out.attrs[\"units\"] = \"¬∞C\"\n",
    "    return out\n",
    "\n",
    "def _coerce_time(da):\n",
    "    if \"time\" in da.dims: return da\n",
    "    try:\n",
    "        dec = xr.decode_cf(da.to_dataset(name=\"_tmp\")).to_array(\"_tmp\")\n",
    "        if \"time\" in dec.dims: return dec\n",
    "    except Exception:\n",
    "        pass\n",
    "    if \"valid_time\" in da.dims:\n",
    "        return da.rename({\"valid_time\":\"time\"})\n",
    "    return da\n",
    "\n",
    "def _align_to_truth_grid(src: xr.DataArray, truth: xr.DataArray) -> xr.DataArray:\n",
    "    s = _ensure_lat_asc(_to_0360(src))\n",
    "    t = _ensure_lat_asc(_to_0360(truth))\n",
    "    try:\n",
    "        if np.array_equal(s.latitude.values, t.latitude.values) and np.array_equal(s.longitude.values, t.longitude.values):\n",
    "            return s\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        return s.reindex_like(t, method=\"nearest\", tolerance={\"latitude\":0.125, \"longitude\":0.125})\n",
    "    except Exception:\n",
    "        pass\n",
    "    s2 = s.sortby([\"latitude\",\"longitude\"]); t2 = t.sortby([\"latitude\",\"longitude\"])\n",
    "    return s2.interp(latitude=t2[\"latitude\"], longitude=t2[\"longitude\"], method=\"nearest\")\n",
    "\n",
    "def _truth_land_mask(truth_da: xr.DataArray) -> xr.DataArray:\n",
    "    return xr.ufuncs.isfinite(truth_da).any(\"time\")\n",
    "\n",
    "def _apply_imd_mask(imd_da: xr.DataArray, mask_ds: xr.Dataset) -> xr.DataArray:\n",
    "    \"\"\"Apply your ocean mask: keep land/coverage where mask is finite.\"\"\"\n",
    "    # If mask is a Dataset, pick the first variable or the precip var name.\n",
    "    m = None\n",
    "    if VAR_P in mask_ds.data_vars:\n",
    "        m = mask_ds[VAR_P]\n",
    "    else:\n",
    "        m = next(iter(mask_ds.data_vars.values()))\n",
    "    m = _ensure_lat_asc(_to_0360(_coerce_time(m)))\n",
    "    imd_da = _ensure_lat_asc(_to_0360(_coerce_time(imd_da)))\n",
    "    m_on = _align_to_truth_grid(m.isel(time=0) if \"time\" in m.dims else m, imd_da.isel(time=0))\n",
    "    return imd_da.where(~xr.ufuncs.isnan(m_on))\n",
    "\n",
    "# --- WeatherBenchX: robust RMSE/MAE spatial-mean series (time on x-axis) ---\n",
    "def _wbx_series(pred: xr.DataArray, truth: xr.DataArray, metric: str):\n",
    "    # WBX wants Datasets with a var name; we'll use \"var\" and valid_time + lead_time=0\n",
    "    def _wbx_pack(da):\n",
    "        da = _coerce_time(da).rename({\"time\":\"valid_time\"})\n",
    "        want = [\"valid_time\"] + [d for d in (\"latitude\",\"longitude\") if d in da.dims]\n",
    "        da = da.transpose(*want)\n",
    "        return da.expand_dims({\"lead_time\":[np.timedelta64(0,\"h\")]})\n",
    "    pred_ds  = xr.Dataset({\"var\": _wbx_pack(pred.astype(\"float32\"))})\n",
    "    truth_ds = xr.Dataset({\"var\": _wbx_pack(truth.astype(\"float32\"))})\n",
    "\n",
    "    if metric.upper() == \"RMSE\":\n",
    "        stats = metrics_base.compute_unique_statistics_for_all_metrics({\"rmse\": deterministic.RMSE()}, pred_ds, truth_ds)\n",
    "        # Use SquaredError block (stable across WBX versions)\n",
    "        se = list(stats[\"SquaredError\"].values())[0]\n",
    "        s  = (se ** 0.5).mean([d for d in (\"latitude\",\"longitude\") if d in se.dims], skipna=True)\n",
    "        if \"lead_time\" in s.dims and s.sizes.get(\"lead_time\",1)==1: s = s.isel(lead_time=0)\n",
    "        return s.rename({\"valid_time\":\"date\"}).squeeze(), \"RMSE\"\n",
    "    else:\n",
    "        stats = metrics_base.compute_unique_statistics_for_all_metrics({\"mae\": deterministic.MAE()}, pred_ds, truth_ds)\n",
    "        ae = list(stats[\"AbsoluteError\"].values())[0]\n",
    "        s  = ae.mean([d for d in (\"latitude\",\"longitude\") if d in ae.dims], skipna=True)\n",
    "        if \"lead_time\" in s.dims and s.sizes.get(\"lead_time\",1)==1: s = s.isel(lead_time=0)\n",
    "        return s.rename({\"valid_time\":\"date\"}).squeeze(), \"MAE\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eae6486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMD panel \n",
    "\n",
    "VAR = VAR_P  # precipitation variable key\n",
    "\n",
    "# widgets (added: month/year splits)\n",
    "region_dd = widgets.Dropdown(options=[\"IMD-Coverage\"], value=\"IMD-Coverage\", description=\"Region:\")\n",
    "metric_dd = widgets.Dropdown(options=[\"RMSE\",\"MAE\",\"SEEPS\"], value=\"RMSE\", description=\"Metric:\")\n",
    "start_month = widgets.Dropdown(options=list(range(1,13)), value=6, description=\"Start month\")\n",
    "end_month   = widgets.Dropdown(options=list(range(1,13)), value=6, description=\"End month\")\n",
    "start_year  = widgets.BoundedIntText(value=2018, min=1900, max=2100, description=\"Start year\")\n",
    "end_year    = widgets.BoundedIntText(value=2018, min=1900, max=2100, description=\"End year\")\n",
    "run_btn = widgets.Button(description=\"Run IMD verification (per-year)\", button_style=\"success\")\n",
    "out = widgets.Output()\n",
    "\n",
    "display(region_dd, metric_dd, widgets.HBox([start_month, end_month, start_year, end_year]), run_btn, out)\n",
    "\n",
    "def _one_year_range(y, m0, m1):\n",
    "    t0 = np.datetime64(pd.Timestamp(year=y, month=m0, day=1))\n",
    "    t1 = np.datetime64(pd.Timestamp(year=y, month=m1, day=1) + pd.offsets.MonthEnd(1))\n",
    "    return t0, t1\n",
    "\n",
    "def _safe_draw(fn):\n",
    "    with out:\n",
    "        out.clear_output(wait=True); plt.close('all'); fn()\n",
    "\n",
    "def on_run(_=None):\n",
    "    def _do():\n",
    "        if ds_imerg is None or ds_imd is None or ds_e5_p is None:\n",
    "            print(\"‚ùå Please load datasets first.\"); return\n",
    "        if VAR not in ds_imerg or VAR not in ds_imd or VAR not in ds_e5_p:\n",
    "            print(f\"‚ùå `{VAR}` must exist in IMERG, IMD, and ERA5.\"); return\n",
    "\n",
    "        m0, m1 = int(start_month.value), int(end_month.value)\n",
    "        y0, y1 = int(start_year.value),  int(end_year.value)\n",
    "        metric = metric_dd.value\n",
    "\n",
    "        # Build IMD truth with your mask applied\n",
    "        imd_full = _normalize_precip(_coerce_time(ds_imd[VAR]))\n",
    "        imd_full = _apply_imd_mask(imd_full, ds_imd_mask)\n",
    "\n",
    "        for y in range(y0, y1+1):\n",
    "            t0, t1 = _one_year_range(y, m0, m1)\n",
    "            imd = imd_full.sel(time=slice(t0, t1))\n",
    "            if imd.sizes.get(\"time\",0) == 0:\n",
    "                print(f\"‚ö†Ô∏è IMD empty for {y}-{m0}..{m1}\"); \n",
    "                continue\n",
    "\n",
    "            # region = IMD coverage (already trimmed by mask)\n",
    "            # align predictors to IMD\n",
    "            imerg = _normalize_precip(_coerce_time(ds_imerg[VAR])).sel(time=slice(t0, t1))\n",
    "            era5  = _normalize_precip(_coerce_time(ds_e5_p[VAR])).sel(time=slice(t0, t1))\n",
    "            imerg_on = _align_to_truth_grid(imerg, imd)\n",
    "            era5_on  = _align_to_truth_grid(era5,  imd)\n",
    "\n",
    "            # time overlap\n",
    "            def _inter(a,b):\n",
    "                T0 = max(np.datetime64(a.time.min().values), np.datetime64(b.time.min().values))\n",
    "                T1 = min(np.datetime64(a.time.max().values), np.datetime64(b.time.max().values))\n",
    "                return a.sel(time=slice(T0,T1)), b.sel(time=slice(T0,T1))\n",
    "            imerg_use, imd_i = _inter(imerg_on, imd)\n",
    "            era5_use,  imd_e = _inter(era5_on,  imd)\n",
    "\n",
    "            # mask oceans/out-of-coverage by IMD finite-any\n",
    "            land_mask_i = xr.ufuncs.isfinite(imd_i).any(\"time\")\n",
    "            land_mask_e = xr.ufuncs.isfinite(imd_e).any(\"time\")\n",
    "            imerg_use = imerg_use.where(land_mask_i); imd_i = imd_i.where(land_mask_i)\n",
    "            era5_use  = era5_use .where(land_mask_e); imd_e = imd_e.where(land_mask_e)\n",
    "\n",
    "            if metric in (\"RMSE\",\"MAE\"):\n",
    "                # WBX deterministic series\n",
    "                s_imerg, _ = _wbx_series(imerg_use, imd_i, metric)\n",
    "                s_era5,  _ = _wbx_series(era5_use,  imd_e, metric)\n",
    "\n",
    "                # two separate plots\n",
    "                fig1, ax1 = plt.subplots(figsize=(9, 3.8))\n",
    "                ax1.plot(pd.to_datetime(s_imerg[\"date\"].values), s_imerg.values)\n",
    "                ax1.set_title(f\"{metric} ‚Äî IMERG vs IMD ‚Äî {y}-{m0}..{m1}\")\n",
    "                ax1.set_ylabel(\"mm/day\"); ax1.grid(True, alpha=0.3); plt.show()\n",
    "\n",
    "                fig2, ax2 = plt.subplots(figsize=(9, 3.8))\n",
    "                ax2.plot(pd.to_datetime(s_era5[\"date\"].values), s_era5.values)\n",
    "                ax2.set_title(f\"{metric} ‚Äî ERA5 vs IMD ‚Äî {y}-{m0}..{m1}\")\n",
    "                ax2.set_ylabel(\"mm/day\"); ax2.grid(True, alpha=0.3); plt.show()\n",
    "\n",
    "                print(f\"Mean {metric} ‚Äî IMERG({y}): {float(s_imerg.mean()):.3f} mm/day\")\n",
    "                print(f\"Mean {metric} ‚Äî ERA5 ({y}): {float(s_era5.mean()):.3f} mm/day\")\n",
    "\n",
    "            else:  # SEEPS (precip only)\n",
    "                # WBX SEEPS needs climatology; build from full masked IMD on same grid\n",
    "                # convert to init_time + lead_time=0\n",
    "                def _to_initlead(da):\n",
    "                    da = da.rename({\"time\":\"init_time\"})\n",
    "                    return da.expand_dims({\"lead_time\":[np.timedelta64(0,\"h\")]})\n",
    "                imerg_w = _to_initlead(imerg_use); era5_w = _to_initlead(era5_use); imd_w = _to_initlead(imd_i)\n",
    "\n",
    "                # build climatology (dayofyear √ó hour) from entire masked IMD record on this grid\n",
    "                fullB = imd_full.sel(latitude=imd_i.latitude, longitude=imd_i.longitude)\n",
    "                # wet threshold (q=0.5) + dry fraction at 0.25 mm/day\n",
    "                dry_thr = 0.25\n",
    "                wet = fullB.where(fullB >= dry_thr)\n",
    "                thr = wet.groupby(\"time.dayofyear\").quantile(0.5, dim=\"time\", skipna=True)\n",
    "                if \"quantile\" in thr.dims: thr = thr.sel(quantile=0.5, drop=True)\n",
    "                dry = (fullB < dry_thr).groupby(\"time.dayofyear\").mean(\"time\", skipna=True)\n",
    "                hours = np.arange(24, dtype=np.int16)\n",
    "                thr = thr.rename({k:\"dayofyear\" for k in thr.dims if k.endswith(\"dayofyear\") or k==\"time_dayofyear\"}).reindex(dayofyear=np.arange(1,367)).fillna(dry_thr).expand_dims(hour=hours).astype(\"float32\")\n",
    "                dry = dry.rename({k:\"dayofyear\" for k in dry.dims if k.endswith(\"dayofyear\") or k==\"time_dayofyear\"}).reindex(dayofyear=np.arange(1,367)).fillna(0.0).expand_dims(hour=hours).clip(0,1).astype(\"float32\")\n",
    "                clim = xr.Dataset({\n",
    "                    f\"{VAR}_seeps_threshold\": thr.rename(f\"{VAR}_seeps_threshold\"),\n",
    "                    f\"{VAR}_seeps_dry_fraction\": dry.rename(f\"{VAR}_seeps_dry_fraction\"),\n",
    "                })\n",
    "\n",
    "                seeps = WBX_SEEPS(variables=[VAR], climatology=clim, dry_threshold_mm=dry_thr, min_p1=0.10, max_p1=0.85)\n",
    "\n",
    "                stats_i = metrics_base.compute_unique_statistics_for_all_metrics({\"seeps\": seeps},\n",
    "                          xr.Dataset({VAR: imerg_w}), xr.Dataset({VAR: imd_w}))\n",
    "                stats_e = metrics_base.compute_unique_statistics_for_all_metrics({\"seeps\": seeps},\n",
    "                          xr.Dataset({VAR: era5_w}),  xr.Dataset({VAR: imd_w}))\n",
    "\n",
    "                s_imerg = list(stats_i[\"SEEPS\"].values())[0].isel(lead_time=0).mean([\"latitude\",\"longitude\"], skipna=True)\n",
    "                s_era5  = list(stats_e[\"SEEPS\"].values())[0].isel(lead_time=0).mean([\"latitude\",\"longitude\"], skipna=True)\n",
    "\n",
    "                fig1, ax1 = plt.subplots(figsize=(9, 3.8))\n",
    "                ax1.plot(pd.to_datetime(s_imerg[\"init_time\"].values), s_imerg.values)\n",
    "                ax1.set_title(f\"SEEPS ‚Äî IMERG vs IMD ‚Äî {y}-{m0}..{m1}\"); ax1.set_ylabel(\"SEEPS (0 best)\"); ax1.grid(True, alpha=0.3); plt.show()\n",
    "\n",
    "                fig2, ax2 = plt.subplots(figsize=(9, 3.8))\n",
    "                ax2.plot(pd.to_datetime(s_era5[\"init_time\"].values), s_era5.values)\n",
    "                ax2.set_title(f\"SEEPS ‚Äî ERA5 vs IMD ‚Äî {y}-{m0}..{m1}\"); ax2.set_ylabel(\"SEEPS (0 best)\"); ax2.grid(True, alpha=0.3); plt.show()\n",
    "\n",
    "                print(f\"Mean SEEPS ‚Äî IMERG({y}): {float(s_imerg.mean()):.3f}\")\n",
    "                print(f\"Mean SEEPS ‚Äî ERA5 ({y}): {float(s_era5.mean()):.3f}\")\n",
    "\n",
    "    _safe_draw(_do)\n",
    "\n",
    "run_btn.on_click(on_run)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87df8c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMD bias maps ‚Äî same cell, but: IMD mask, no smoothing, correct orientation\n",
    "\n",
    "years_txt   = widgets.Text(value=\"2018-2021\", description=\"Years (YYYY-YYYY):\")\n",
    "vmax_txt    = widgets.Text(value=\"50\",        description=\"Abs max (mm)\")\n",
    "show_era5   = widgets.Checkbox(value=True,    description=\"ERA5 vs IMD\")\n",
    "show_imerg  = widgets.Checkbox(value=True,    description=\"IMERG vs IMD\")\n",
    "btn_run_map = widgets.Button(description=\"Run bias maps\", button_style=\"info\")\n",
    "out_map     = widgets.Output()\n",
    "\n",
    "display(Markdown(\"### Spatial bias maps ‚Äî **IMD truth** (May‚ÄìJuly mean, masked to IMD coverage, no smoothing)\"))\n",
    "display(widgets.HBox([years_txt, vmax_txt, show_era5, show_imerg, btn_run_map]), out_map)\n",
    "\n",
    "def _mjj_years(da, y0, y1):\n",
    "    da = da.sel(time=da.time.dt.month.isin([5,6,7]))\n",
    "    return da.sel(time=slice(f\"{y0}-01-01\", f\"{y1}-12-31\"))\n",
    "\n",
    "@out_map.capture(clear_output=True)\n",
    "def _run_bias_maps(_):\n",
    "    if any(v is None for v in [ds_imd, ds_imerg, ds_e5_p]):\n",
    "        print(\"‚ùå Please load IMD, IMERG, ERA5 first.\"); return\n",
    "    if VAR not in ds_imd or VAR not in ds_imerg or VAR not in ds_e5_p:\n",
    "        print(f\"‚ùå `{VAR}` must exist in IMD, IMERG, ERA5.\"); return\n",
    "\n",
    "    try:\n",
    "        y0, y1 = [int(x) for x in years_txt.value.strip().split(\"-\")]\n",
    "    except Exception:\n",
    "        print(\"‚ö†Ô∏è Could not parse years, using full overlap.\"); y0, y1 = (1900, 2100)\n",
    "\n",
    "    # IMD truth with mask (excludes oceans)\n",
    "    imd   = _apply_imd_mask(_normalize_precip(_coerce_time(ds_imd[VAR])), ds_imd_mask)\n",
    "    imerg = _normalize_precip(_coerce_time(ds_imerg[VAR]))\n",
    "    era5  = _normalize_precip(_coerce_time(ds_e5_p[VAR]))\n",
    "\n",
    "    # Select MJJ + years (then auto-overlap)\n",
    "    imd_mjj   = _mjj_years(imd,   y0, y1)\n",
    "    imerg_mjj = _mjj_years(imerg, y0, y1)\n",
    "    era5_mjj  = _mjj_years(era5,  y0, y1)\n",
    "\n",
    "    # Align to IMD grid + intersection in time\n",
    "    imerg_on = _align_to_truth_grid(imerg_mjj, imd_mjj)\n",
    "    era5_on  = _align_to_truth_grid(era5_mjj,  imd_mjj)\n",
    "\n",
    "    t0 = max(np.datetime64(imd_mjj.time.min().values),\n",
    "             np.datetime64(imerg_on.time.min().values),\n",
    "             np.datetime64(era5_on.time.min().values))\n",
    "    t1 = min(np.datetime64(imd_mjj.time.max().values),\n",
    "             np.datetime64(imerg_on.time.max().values),\n",
    "             np.datetime64(era5_on.time.max().values))\n",
    "    imd_use   = imd_mjj.sel(time=slice(t0, t1))\n",
    "    imerg_use = imerg_on.sel(time=slice(t0, t1))\n",
    "    era5_use  = era5_on.sel(time=slice(t0, t1))\n",
    "\n",
    "    # land/coverage mask (finite-any over window)\n",
    "    land_mask = xr.ufuncs.isfinite(imd_use).any(\"time\")\n",
    "    imerg_bias = (imerg_use - imd_use).where(land_mask).mean(\"time\", skipna=True)\n",
    "    era5_bias  = (era5_use  - imd_use).where(land_mask).mean(\"time\",  skipna=True)\n",
    "\n",
    "    vmax = float(vmax_txt.value or 50.0); vmin = -vmax\n",
    "    ncols = int(show_era5.value) + int(show_imerg.value)\n",
    "    if ncols == 0:\n",
    "        print(\"‚ö†Ô∏è Select at least one predictor.\"); return\n",
    "\n",
    "    fig, axs = plt.subplots(1, ncols, figsize=(6.0*ncols, 4.8), constrained_layout=True)\n",
    "    if ncols == 1: axs = [axs]\n",
    "    i = 0\n",
    "    if show_era5.value:\n",
    "        era5_bias.plot(ax=axs[i], x=\"longitude\", y=\"latitude\", vmin=vmin, vmax=vmax,\n",
    "                       cmap=\"RdBu_r\", cbar_kwargs={\"label\":\"mm/day\"})\n",
    "        axs[i].set_title(\"Bias: ERA5 ‚àí IMD (mm/day)\"); axs[i].grid(True, alpha=0.2); i += 1\n",
    "    if show_imerg.value:\n",
    "        imerg_bias.plot(ax=axs[i], x=\"longitude\", y=\"latitude\", vmin=vmin, vmax=vmax,\n",
    "                        cmap=\"RdBu_r\", cbar_kwargs={\"label\":\"mm/day\"})\n",
    "        axs[i].set_title(\"Bias: IMERG ‚àí IMD (mm/day)\"); axs[i].grid(True, alpha=0.2)\n",
    "\n",
    "    y0p = pd.to_datetime(str(imd_use.time.min().values)).year\n",
    "    y1p = pd.to_datetime(str(imd_use.time.max().values)).year\n",
    "    display(Markdown(f\"*Mean bias over **May‚ÄìJuly**, years **{y0p}‚Äì{y1p}** ‚Äî **masked to IMD coverage** (no smoothing).*\"))\n",
    "    plt.show()\n",
    "\n",
    "btn_run_map.on_click(_run_bias_maps)\n",
    "print(\"‚úÖ IMD bias-map panel updated (mask, no smoothing, correct orientation).\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIFS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
