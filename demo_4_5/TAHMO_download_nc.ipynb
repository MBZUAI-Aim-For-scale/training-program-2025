{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dabf5d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import TAHMO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e21b54b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = TAHMO.apiWrapper()\n",
    "api.setCredentials('Data@TAHMO', \"fzEhB9f'lG)!M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ae28e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API request: services/assets/v2/stations\n",
      "Account has access to stations: TA00189, TA00767\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Get metadata from all stations that your account has access to.\n",
    "stations = api.getStations()\n",
    "print('Account has access to stations: %s' % ', '.join(list(stations)))\n",
    "stations_list = list(stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffa99c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_metadata = {\"TA00189\": {\"latitude\": -0.85052, \"longitude\": 35.91223},\n",
    "                     \"TA00767\": {\"latitude\": -0.7075705, \"longitude\": 31.4021381}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39899dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API request: services/assets/v2/variables\n",
      "Available variables in TAHMO API:\n",
      "Atmospheric pressure [kPa] with shortcode \"ap\"\n",
      "Depth of water [mm] with shortcode \"dw\"\n",
      "Electrical conductivity of precipitation [mS/cm] with shortcode \"ec\"\n",
      "Electrical conductivity of water [mS/cm] with shortcode \"ew\"\n",
      "Lightning distance [km] with shortcode \"ld\"\n",
      "Lightning events [-] with shortcode \"le\"\n",
      "Shortwave radiation [W/m2] with shortcode \"ra\"\n",
      "Soil moisture content [m3/m3] with shortcode \"sm\"\n",
      "Soil temperature [degrees Celsius] with shortcode \"st\"\n",
      "Surface air temperature [degrees Celsius] with shortcode \"te\"\n",
      "Vapor pressure [kPa] with shortcode \"vp\"\n",
      "Wind gusts [m/s] with shortcode \"wg\"\n",
      "Wind speed [m/s] with shortcode \"ws\"\n",
      "Temperature of humidity sensor [degrees Celsius] with shortcode \"ht\"\n",
      "X-axis level [degrees] with shortcode \"tx\"\n",
      "Y-axis level [degrees] with shortcode \"ty\"\n",
      "Logger battery percentage [-] with shortcode \"lb\"\n",
      "Logger reference pressure [kPa] with shortcode \"lp\"\n",
      "Logger temperature [degrees Celsius] with shortcode \"lt\"\n",
      "Cumulative precipitation [mm] with shortcode \"cp\"\n",
      "Water level [m] with shortcode \"wl\"\n",
      "Water velocity [m/s] with shortcode \"wv\"\n",
      "Precipitation [mm] with shortcode \"pr\"\n",
      "Relative humidity [-] with shortcode \"rh\"\n",
      "Wind direction [degrees] with shortcode \"wd\"\n",
      "Soil electrical conductivity [mS/cm] with shortcode \"se\"\n",
      "Water temperature [degrees Celsius] with shortcode \"tw\"\n",
      "Water discharge [m3/s] with shortcode \"wq\"\n",
      "Matric potential [kPa] with shortcode \"mp\"\n",
      "Precipitation drop count [-] with shortcode \"pd\"\n",
      "Precipitation tip count [-] with shortcode \"pt\"\n",
      "Tilt angle [degrees] with shortcode \"ta\"\n"
     ]
    }
   ],
   "source": [
    "# Example 2: Get all variables and units from the TAHMO API.\n",
    "variables = api.getVariables()\n",
    "print('Available variables in TAHMO API:')\n",
    "for variable in variables:\n",
    "    print('%s [%s] with shortcode \"%s\"' %\n",
    "          (variables[variable]['description'], variables[variable]['units'], variables[variable]['shortcode']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b64c637",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_of_interest = [\"te\", \"pr\", \"cp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f460fbc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for station TA00189\n",
      "API request: services/measurements/v2/stations/TA00189/measurements/controlled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/TAHMO/__init__.py:184: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df['end'].iloc[-1] = pd.Timestamp(endDate)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API request: services/measurements/v2/stations/TA00189/measurements/controlled\n",
      "API request: services/measurements/v2/stations/TA00189/measurements/controlled\n",
      "API request: services/measurements/v2/stations/TA00189/measurements/controlled\n",
      "API request: services/measurements/v2/stations/TA00189/measurements/controlled\n",
      "API request: services/measurements/v2/stations/TA00189/measurements/controlled\n",
      "API request: services/measurements/v2/stations/TA00189/measurements/controlled\n",
      "API request: services/measurements/v2/stations/TA00189/measurements/controlled\n",
      "Downloading data for station TA00767\n",
      "API request: services/measurements/v2/stations/TA00767/measurements/controlled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/TAHMO/__init__.py:184: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df['end'].iloc[-1] = pd.Timestamp(endDate)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API request: services/measurements/v2/stations/TA00767/measurements/controlled\n",
      "API request: services/measurements/v2/stations/TA00767/measurements/controlled\n",
      "API request: services/measurements/v2/stations/TA00767/measurements/controlled\n",
      "API request: services/measurements/v2/stations/TA00767/measurements/controlled\n",
      "API request: services/measurements/v2/stations/TA00767/measurements/controlled\n",
      "API request: services/measurements/v2/stations/TA00767/measurements/controlled\n",
      "API request: services/measurements/v2/stations/TA00767/measurements/controlled\n"
     ]
    }
   ],
   "source": [
    "measurements = {}\n",
    "startDate = '2018-01-01'\n",
    "endDate = '2025-07-31'\n",
    "for station in stations_list:\n",
    "    print('Downloading data for station %s' % station)\n",
    "    measurements[station] = api.getMeasurements(station, startDate=startDate, endDate=endDate, variables=variables_of_interest)\n",
    "    measurements[station].index.name = 'Timestamp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5977a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             te   pr\n",
      "Timestamp                           \n",
      "2020-12-01 11:30:00+00:00   NaN  NaN\n",
      "2020-12-01 11:35:00+00:00   NaN  NaN\n",
      "2020-12-01 11:40:00+00:00  28.3  0.0\n",
      "2020-12-01 11:45:00+00:00  28.3  0.0\n",
      "2020-12-01 11:50:00+00:00  28.2  0.0\n",
      "...                         ...  ...\n",
      "2025-07-30 23:40:00+00:00  17.6  0.0\n",
      "2025-07-30 23:45:00+00:00  17.7  0.0\n",
      "2025-07-30 23:50:00+00:00  17.6  0.0\n",
      "2025-07-30 23:55:00+00:00  17.5  0.0\n",
      "2025-07-31 00:00:00+00:00  17.5  0.0\n",
      "\n",
      "[490293 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(measurements['TA00767'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d934eead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             te   pr\n",
      "Timestamp                           \n",
      "2018-01-01 00:00:00+00:00  18.7  0.0\n",
      "2018-01-01 00:05:00+00:00  18.5  0.0\n",
      "2018-01-01 00:10:00+00:00  18.6  0.0\n",
      "2018-01-01 00:15:00+00:00  18.5  0.0\n",
      "2018-01-01 00:20:00+00:00  18.4  0.0\n",
      "...                         ...  ...\n",
      "2025-07-30 23:40:00+00:00  16.7  0.0\n",
      "2025-07-30 23:45:00+00:00  16.8  0.0\n",
      "2025-07-30 23:50:00+00:00  16.7  0.0\n",
      "2025-07-30 23:55:00+00:00  16.7  0.0\n",
      "2025-07-31 00:00:00+00:00  16.7  0.0\n",
      "\n",
      "[796812 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(measurements['TA00189'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "371d44db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "# examples you showed:\n",
    "# station_metadata = {\"TA00189\": {\"latitude\": -0.85052, \"longitude\": 35.91223},\n",
    "#                     \"TA00767\": {\"latitude\": -0.7075705, \"longitude\": 31.4021381}}\n",
    "# measurements is a dict: {station_id: DataFrame[te, pr] indexed by Timestamp}\n",
    "\n",
    "def to_station_datasets(measurements: dict, station_metadata: dict) -> dict:\n",
    "    \"\"\"Return {station_id: xr.Dataset} with coords time, latitude, longitude.\"\"\"\n",
    "    ds_by_station = {}\n",
    "\n",
    "    for sid, df in measurements.items():\n",
    "        # Ensure expected columns exist\n",
    "        if not {'te', 'pr'}.issubset(df.columns):\n",
    "            raise ValueError(f\"{sid}: DataFrame must have columns 'te' and 'pr'.\")\n",
    "\n",
    "        # Make sure index is datetime and in UTC-naive (xarray stores tz-naive)\n",
    "        idx = df.index\n",
    "        if not isinstance(idx, pd.DatetimeIndex):\n",
    "            raise TypeError(f\"{sid}: index must be a DatetimeIndex.\")\n",
    "        if idx.tz is None:\n",
    "            time = idx  # assume already UTC-naive\n",
    "        else:\n",
    "            time = idx.tz_convert('UTC').tz_localize(None)\n",
    "\n",
    "        # Get lat/lon (raise if missing)\n",
    "        try:\n",
    "            lat = float(station_metadata[sid]['latitude'])\n",
    "            lon = float(station_metadata[sid]['longitude'])\n",
    "        except KeyError:\n",
    "            raise KeyError(f\"Missing lat/lon for station {sid} in station_metadata.\")\n",
    "\n",
    "        # Build dataset: lat/lon as scalar coords; time as 1-D coord\n",
    "        ds = xr.Dataset(\n",
    "            data_vars={\n",
    "                'te': (('time',), df['te'].to_numpy()),\n",
    "                'pr': (('time',), df['pr'].to_numpy()),\n",
    "            },\n",
    "            coords={\n",
    "                'time': pd.DatetimeIndex(time.values),      # 1-D\n",
    "                'latitude': lat,                     # scalar coord\n",
    "                'longitude': lon,                    # scalar coord\n",
    "            },\n",
    "            attrs={'station_id': sid}\n",
    "        )\n",
    "\n",
    "        # Optional: set dtype, names, and encoding\n",
    "        ds['te'] = ds['te'].astype('float32')\n",
    "        ds['pr'] = ds['pr'].astype('float32')\n",
    "        ds['te'].attrs.update(units='Â°C', long_name='air_temperature')\n",
    "        ds['pr'].attrs.update(units='mm', long_name='precipitation')\n",
    "        ds = ds.dropna(dim='time', how='all')  # drop times where both vars are NaN\n",
    "        ds = ds.rename({'te': 'temperature', 'pr': 'precipitation'})\n",
    "        ds_by_station[sid] = ds\n",
    "\n",
    "    return ds_by_station\n",
    "\n",
    "# Usage\n",
    "station_datasets = to_station_datasets(measurements, station_metadata)\n",
    "\n",
    "# Example: access one\n",
    "ds_767 = station_datasets['TA00767']\n",
    "ds_189 = station_datasets['TA00189']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ad18ec7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample the temperature to daily mean\n",
    "# resample the precipitation to daily sum\n",
    "\n",
    "ds_767_daily = xr.Dataset({\n",
    "    'tavg': ds_767['temperature'].resample(time='1D').mean(),\n",
    "    'total_precipitation_24hr': ds_767['precipitation'].resample(time='1D').sum()\n",
    "})\n",
    "\n",
    "ds_189_daily = xr.Dataset({\n",
    "    'tavg': ds_189['temperature'].resample(time='1D').mean(),\n",
    "    'total_precipitation_24hr': ds_189['precipitation'].resample(time='1D').sum()\n",
    "})\n",
    "\n",
    "# save these datasets to netCDF files\n",
    "ds_767_daily.to_netcdf('TAHMO_00767_daily.nc')\n",
    "ds_189_daily.to_netcdf('TAHMO_00189_daily.nc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "benchmarks_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
