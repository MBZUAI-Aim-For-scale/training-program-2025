{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe938765",
   "metadata": {},
   "source": [
    "\n",
    "# üß™ Demo 5: Ground Truth Challenge ‚Äî Validate Your Forecast with Your Data (Demo 4‚Äìstyle)\n",
    "\n",
    "This notebook mirrors **Demo 4** (widgets, regions, WeatherBench‚ÄëX), and adds the ability to plug in **your own ground truth**:\n",
    "- **Default**: ERA5 from Google Cloud Storage (no downloads)\n",
    "- **Optional**: Point **CSV** (`time,lat,lon,value`) with time tolerance\n",
    "- **Optional**: **Gridded** NetCDF/Zarr file (local path or `gs://‚Ä¶`)\n",
    "\n",
    "You can compare **Global vs Local** regions and compute **RMSE** (and **ACC** if GT supports climatology).\n",
    "\n",
    "> Tip: start with ERA5 as truth; once it runs, try your CSV/NetCDF.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdf58205",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown, clear_output\n",
    "import fsspec, gcsfs, os, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# WeatherBench-X\n",
    "from weatherbenchX.metrics import deterministic\n",
    "from weatherbenchX.metrics import base as metrics_base\n",
    "from weatherbenchX import aggregation\n",
    "from weatherbenchX import time_chunks\n",
    "\n",
    "ERA5_PATH = \"gs://gcp-public-data-arco-era5/ar/full_37-1h-0p25deg-chunk-1.zarr-v3\"\n",
    "CLIM_PATH = \"gs://weatherbench2/datasets/era5-hourly-climatology/1990-2019_6h_1440x721.zarr\"\n",
    "G = 9.80665  # m s^-2\n",
    "\n",
    "# Regions (same spirit as Demo-4)\n",
    "DOMAIN_DEFINITIONS = {\n",
    "    \"Global\": {\"latitude\": slice(90, -90), \"longitude\": slice(0, 360)},\n",
    "    \"Northern Hemisphere\": {\"latitude\": slice(90, 0), \"longitude\": slice(0, 360)},\n",
    "    \"Tropics\": {\"latitude\": slice(23.5, -23.5), \"longitude\": slice(0, 360)},\n",
    "    \"Bangladesh\": {\"latitude\": slice(26.7, 20.7), \"longitude\": slice(88.0, 92.7)},\n",
    "    \"Chile\": {\"latitude\": slice(-17.5, -56.0), \"longitude\": slice(284.0, 294.0)},\n",
    "    \"Nigeria\": {\"latitude\": slice(14.7, 4.0), \"longitude\": slice(2.7, 14.7)},\n",
    "    \"Ethiopia\": {\"latitude\": slice(14.9, 3.4), \"longitude\": slice(33.0, 48.0)},\n",
    "    \"Kenya\": {\"latitude\": slice(5.0, -4.7), \"longitude\": slice(33.9, 41.9)},\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed113ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_lon360(ds: xr.Dataset) -> xr.Dataset:\n",
    "    if float(ds.longitude.min()) < 0 or float(ds.longitude.max()) <= 180:\n",
    "        ds = ds.assign_coords(longitude=(ds.longitude % 360))\n",
    "    return ds.sortby([\"latitude\", \"longitude\"])\n",
    "\n",
    "def ensure_ecmwf_names(ds: xr.Dataset) -> xr.Dataset:\n",
    "    ren = {}\n",
    "    if \"lat\" in ds.coords: ren[\"lat\"] = \"latitude\"\n",
    "    if \"lon\" in ds.coords: ren[\"lon\"] = \"longitude\"\n",
    "    if ren: ds = ds.rename(ren)\n",
    "    return ensure_lon360(ds)\n",
    "\n",
    "def ensure_lead_time(ds: xr.Dataset) -> xr.Dataset:\n",
    "    \"\"\"\n",
    "    Guarantee dims ('init_time','lead_time','latitude','longitude') from ('time'|'init_time','step',...).\n",
    "    Uses ndarray values to avoid the 'DataArray is ambiguous' error.\n",
    "    \"\"\"\n",
    "    if \"init_time\" not in ds.coords and \"time\" in ds.coords:\n",
    "        ds = ds.rename({\"time\": \"init_time\"})\n",
    "    if \"lead_time\" not in ds.dims:\n",
    "        if \"step\" not in ds.dims:\n",
    "            raise ValueError(\"Dataset has neither 'lead_time' nor 'step' dimension.\")\n",
    "        step = ds[\"step\"]\n",
    "        if np.issubdtype(step.dtype, np.number):\n",
    "            lt_vals = pd.to_timedelta(step.values, unit=\"h\").astype(\"timedelta64[ns]\")\n",
    "        else:\n",
    "            # already timedelta-like\n",
    "            lt_vals = step.values.astype(\"timedelta64[ns]\")\n",
    "        ds = ds.assign_coords(lead_time=(\"step\", lt_vals))   # <- ndarray, not DataArray\n",
    "        ds = ds.swap_dims({\"step\": \"lead_time\"})\n",
    "    return ds\n",
    "\n",
    "def open_era5_subset(needed_vars):\n",
    "    # Open ERA5 from GCS lazily; select only needed vars\n",
    "    ds = xr.open_zarr(ERA5_PATH, chunks=None, storage_options={\"token\":\"anon\"})\n",
    "    keep = [v for v in needed_vars if v in ds]\n",
    "    if not keep:\n",
    "        raise KeyError(f\"None of {needed_vars} exist in ERA5 store.\")\n",
    "    return ds[keep]\n",
    "\n",
    "def build_era5_truth(forecast_ds: xr.Dataset, fvars):\n",
    "    # Map AIFS names -> ERA5 names\n",
    "    var_map = {\"2t\":\"2m_temperature\", \"tp\":\"total_precipitation\", \"z_500\":\"geopotential\"}\n",
    "    era5_vars = [var_map.get(v, v) for v in fvars]\n",
    "    full = open_era5_subset(era5_vars)\n",
    "\n",
    "    # Build truth dataset with AIFS-style var names\n",
    "    gt = xr.Dataset()\n",
    "    if \"2m_temperature\" in full: gt[\"2t\"] = full[\"2m_temperature\"]\n",
    "    if \"total_precipitation\" in full: gt[\"tp\"] = full[\"total_precipitation\"]\n",
    "    if \"geopotential\" in full: gt[\"z_500\"] = full[\"geopotential\"].sel(level=500).drop_vars(\"level\") / G\n",
    "\n",
    "    # Slice time window to forecast range\n",
    "    init = forecast_ds[\"init_time\"].min().values\n",
    "    end  = (init + forecast_ds[\"lead_time\"].max().astype(\"timedelta64[ns]\")).astype(\"datetime64[ns]\")\n",
    "    return gt.sel(time=slice(init, end))\n",
    "\n",
    "def load_climatology_for_acc(fvars):\n",
    "    # WB-X climatology zarr; rename to AIFS var names\n",
    "    raw = xr.open_zarr(CLIM_PATH, storage_options={\"token\":\"anon\"})\n",
    "    ren = {}\n",
    "    if \"2m_temperature\" in raw: ren[\"2m_temperature\"] = \"2t\"\n",
    "    if \"geopotential\" in raw:   ren[\"geopotential\"]    = \"z_500\"\n",
    "    if \"total_precipitation_6hr\" in raw: ren[\"total_precipitation_6hr\"] = \"tp\"\n",
    "    clim = raw.rename_vars(ren)\n",
    "    keep = [v for v in fvars if v in clim]\n",
    "    clim = clim[keep]\n",
    "    if \"z_500\" in clim and \"level\" in clim[\"z_500\"].dims:\n",
    "        clim[\"z_500\"] = clim[\"z_500\"].sel(level=500).drop_vars(\"level\")\n",
    "    return clim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43c591e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c75b0487f55c4581a6353cdfb447e8eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='init_ERA5_20230630T00_lead_360.nc', description='Forecast file:', layout=Layout(width='80%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae048c236eb54d83a0e4acbb54e5027d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='primary', description='Load Forecast', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f74e713073d14bbb80666cfedadeff8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Path to your Demo-2 forecast\n",
    "forecast_vars = ['2t', 'z_500', 'tp']\n",
    "\n",
    "# Mapping from forecast variable names ‚Üí ERA5 names\n",
    "var_map = {\n",
    "    \"2t\": \"2m_temperature\",\n",
    "    \"tp\": \"total_precipitation\",\n",
    "    \"z_500\": \"geopotential\",\n",
    "}\n",
    "forecast_path = widgets.Text(\n",
    "    description='Forecast file:',\n",
    "    value=\"init_ERA5_20230630T00_lead_360.nc\",  # <‚Äî change if needed\n",
    "    layout=widgets.Layout(width='80%')\n",
    ")\n",
    "\n",
    "load_button = widgets.Button(description=\"Load Forecast\", button_style=\"primary\")\n",
    "load_out = widgets.Output()\n",
    "\n",
    "display(forecast_path, load_button, load_out)\n",
    "\n",
    "forecast_ds = None\n",
    "\n",
    "def on_load(_):\n",
    "    global forecast_ds\n",
    "    load_out.clear_output()\n",
    "    with load_out:\n",
    "        try:\n",
    "            ds = xr.open_dataset(forecast_path.value)\n",
    "            ds = ensure_ecmwf_names(ds)\n",
    "            ds = ensure_lead_time(ds)\n",
    "            forecast_ds = ds\n",
    "            display(Markdown(\"‚úÖ Forecast loaded & normalized.\"))\n",
    "            display(forecast_ds)\n",
    "        except Exception as e:\n",
    "            display(Markdown(f\"‚ùå Error loading forecast: `{e}`\"))\n",
    "\n",
    "load_button.on_click(on_load)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7189c85c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edd4787f61f44e97a91a2b06eee8441b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Cell 5 (REPLACE ME) ---\n",
    "# Build ERA5 truth aligned to forecast, but only for the variables you will verify.\n",
    "# This keeps memory low and avoids kernel crashes.\n",
    "\n",
    "era5_out = widgets.Output()\n",
    "display(era5_out)\n",
    "\n",
    "# ‚¨áÔ∏è choose which variables to pull NOW (start with just [\"2t\"]; add \"z_500\" or \"tp\" later)\n",
    "vars_for_this_run = [\"2t\"]   # <<< IMPORTANT: keep only \"2t\" first; then try [\"z_500\"], then [\"tp\"]\n",
    "\n",
    "# Map AIFS ‚Üí ERA5\n",
    "VAR_MAP = {\"2t\": \"2m_temperature\", \"z_500\": \"geopotential\", \"tp\": \"total_precipitation\"}\n",
    "\n",
    "def open_era5_subset_min(forecast_ds: xr.Dataset, wanted: list[str]) -> xr.Dataset:\n",
    "    # 1) compute time window from forecast (do not touch data yet)\n",
    "    init = forecast_ds[\"init_time\"].min().values\n",
    "    end  = (init + forecast_ds[\"lead_time\"].max().astype(\"timedelta64[ns]\")).astype(\"datetime64[ns]\")\n",
    "\n",
    "    # 2) open ERA5 lazily, select only needed variables\n",
    "    keep = []\n",
    "    ds_all = xr.open_zarr(ERA5_PATH, chunks={\"time\": 24}, storage_options={\"token\": \"anon\"})\n",
    "    for v in wanted:\n",
    "        evar = VAR_MAP.get(v, v)\n",
    "        if evar in ds_all:\n",
    "            keep.append(evar)\n",
    "\n",
    "    if not keep:\n",
    "        raise KeyError(f\"No matching ERA5 variables for {wanted}\")\n",
    "\n",
    "    # 3) light time slice first (still lazy)\n",
    "    ds = ds_all[keep].sel(time=slice(init, end))\n",
    "\n",
    "    # 4) build GT in AIFS names, with minimal compute\n",
    "    gt = xr.Dataset()\n",
    "    if \"2m_temperature\" in ds and \"2t\" in wanted:\n",
    "        gt[\"2t\"] = ds[\"2m_temperature\"]\n",
    "\n",
    "    if \"geopotential\" in ds and \"z_500\" in wanted:\n",
    "        # pick level=500 lazily; divide by g (still lazy)\n",
    "        gt[\"z_500\"] = (ds[\"geopotential\"].sel(level=500).drop_vars(\"level\")) / G\n",
    "\n",
    "    if \"total_precipitation\" in ds and \"tp\" in wanted:\n",
    "        # ERA5 hourly accumulations ‚Üí 6-hour sums.\n",
    "        # Do rolling AFTER the time slice to keep it small.\n",
    "        tp1h = ds[\"total_precipitation\"]\n",
    "        gt[\"tp\"] = tp1h.rolling(time=6, min_periods=6).sum()\n",
    "\n",
    "    return gt\n",
    "\n",
    "era5_ds = None\n",
    "with era5_out:\n",
    "    try:\n",
    "        if forecast_ds is None:\n",
    "            raise RuntimeError(\"Load the forecast first (previous cell).\")\n",
    "\n",
    "        # Safety: check the forecast actually contains the variable(s) we‚Äôll verify later\n",
    "        missing = [v for v in vars_for_this_run if v not in forecast_ds.data_vars]\n",
    "        if missing:\n",
    "            display(Markdown(f\"‚ö†Ô∏è Forecast does not have {missing}. I will pull only the overlap.\"))\n",
    "\n",
    "        # open ERA5 for ONLY the vars we‚Äôll verify now\n",
    "        era5_ds = open_era5_subset_min(forecast_ds, vars_for_this_run)\n",
    "        display(Markdown(f\"‚úÖ ERA5 truth opened for {list(era5_ds.data_vars)} and time-aligned.\"))\n",
    "        display(era5_ds)\n",
    "    except Exception as e:\n",
    "        display(Markdown(f\"‚ùå ERA5 load error: `{e}`\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8650e403",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_statistics_in_chunks(forecast_ds, era5_ds, metrics, fvars, chunk_size=48):\n",
    "    \"\"\"Chunked compute, but only for the selected variables (fvars).\"\"\"\n",
    "    n = forecast_ds.sizes[\"init_time\"]\n",
    "    parts = []\n",
    "    for i in range(0, n, chunk_size):\n",
    "        sl = slice(i, min(i + chunk_size, n))\n",
    "        # ‚¨áÔ∏è subset to the exact variables on BOTH sides\n",
    "        f_chunk = forecast_ds[fvars].isel(init_time=sl)\n",
    "        t_chunk = era5_ds[fvars].isel(time=sl)\n",
    "        stats = metrics_base.compute_unique_statistics_for_all_metrics(metrics, f_chunk, t_chunk)\n",
    "        parts.append(stats)\n",
    "    final = {}\n",
    "    for st in parts:\n",
    "        for k, v in st.items():\n",
    "            final[k] = xr.concat([final[k], v], dim=\"time\") if k in final else v\n",
    "    return final\n",
    "\n",
    "def run_verification(forecast_ds, era5_ds, metric_name, fvars):\n",
    "    \"\"\"Compute metrics on the FULL grid (no region slicing here).\"\"\"\n",
    "    if metric_name == \"RMSE\":\n",
    "        mets = {\"rmse\": deterministic.RMSE()}\n",
    "    else:\n",
    "        clim = load_climatology_for_acc(fvars)\n",
    "        mets = {\"ACC\": deterministic.ACC(climatology=clim)}\n",
    "    return compute_statistics_in_chunks(forecast_ds, era5_ds, mets, fvars=fvars, chunk_size=48)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ac3e21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "158d970be64b4a1fa4bc3527fb6bb1fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Region:', options=('Global', 'Northern Hemisphere', 'Tropics', 'Bangladesh', 'Chile', 'N‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "186ef7d5a76447d1b7f38223d37d159b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Metric:', options=('RMSE', 'ACC'), value='RMSE')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3724031289b14333a47f2b8bc8711d21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Variable:', options=('2t',), value='2t')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "220847e5f3334631a626b97bd7298117",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Run Verification', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecc61892d0dd4a15b41a167501ebed31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if forecast_ds is None or era5_ds is None:\n",
    "    display(Markdown(\"‚ÑπÔ∏è Load forecast (Cell 4) and ERA5 truth (Cell 5) first.\"))\n",
    "else:\n",
    "    region_selector = widgets.Dropdown(options=list(DOMAIN_DEFINITIONS.keys()),\n",
    "                                       value=\"Global\", description=\"Region:\")\n",
    "    metric_selector = widgets.Dropdown(options=[\"RMSE\",\"ACC\"],\n",
    "                                       value=\"RMSE\", description=\"Metric:\")\n",
    "    available = [v for v in vars_for_this_run if v in forecast_ds.data_vars and v in era5_ds.data_vars]\n",
    "    if not available:\n",
    "        available = [v for v in forecast_ds.data_vars if v in [\"2t\",\"z_500\",\"tp\"] and v in era5_ds.data_vars]\n",
    "    variable_selector = widgets.Dropdown(options=available, value=available[0], description=\"Variable:\")\n",
    "    run_btn = widgets.Button(description=\"Run Verification\", button_style=\"success\")\n",
    "    out = widgets.Output()\n",
    "    display(region_selector, metric_selector, variable_selector, run_btn, out)\n",
    "\n",
    "    def on_run(_):\n",
    "        out.clear_output(wait=True)\n",
    "        with out:\n",
    "            try:\n",
    "                region = DOMAIN_DEFINITIONS[region_selector.value]\n",
    "                metric = metric_selector.value\n",
    "                var    = variable_selector.value\n",
    "\n",
    "                # 1) Compute metrics on full grid\n",
    "                stats = run_verification(forecast_ds, era5_ds, metric, [var])\n",
    "\n",
    "                # 2) Region slicing done HERE (after metrics), then spatial mean\n",
    "                box = region\n",
    "                if metric == \"RMSE\":\n",
    "                    se = stats[\"SquaredError\"][var]\n",
    "                    lat_slice = _lat_slice_for(se, box)\n",
    "                    se_reg = se.sel(latitude=lat_slice, longitude=box[\"longitude\"]).mean(dim=[\"latitude\",\"longitude\"])\n",
    "                    rmse = np.sqrt(se_reg).assign_coords(lead_time_days = se_reg['lead_time'] / np.timedelta64(1,'D'))\n",
    "                    ax = rmse.plot(x='lead_time_days', figsize=(8,4))\n",
    "                    ax.set_title(f\"RMSE ‚Äî {var} ‚Äî {region_selector.value}\")\n",
    "                    ax.set_xlabel(\"Forecast time (days)\"); ax.set_ylabel(\"RMSE\")\n",
    "                    plt.show()\n",
    "                else:\n",
    "                    pa = stats['SquaredPredictionAnomaly'][var]\n",
    "                    ta = stats['SquaredTargetAnomaly'][var]\n",
    "                    co = stats['AnomalyCovariance'][var]\n",
    "\n",
    "                    lat_slice = _lat_slice_for(pa, box)\n",
    "                    pa = pa.sel(latitude=lat_slice, longitude=box[\"longitude\"]).mean(dim=[\"latitude\",\"longitude\"])\n",
    "                    ta = ta.sel(latitude=lat_slice, longitude=box[\"longitude\"]).mean(dim=[\"latitude\",\"longitude\"])\n",
    "                    co = co.sel(latitude=lat_slice, longitude=box[\"longitude\"]).mean(dim=[\"latitude\",\"longitude\"])\n",
    "\n",
    "                    acc = (co / np.sqrt(pa * ta)).assign_coords(lead_time_days = pa['lead_time'] / np.timedelta64(1,'D'))\n",
    "                    ax = acc.plot(x='lead_time_days', figsize=(8,4))\n",
    "                    ax.set_title(f\"ACC ‚Äî {var} ‚Äî {region_selector.value}\")\n",
    "                    ax.set_xlabel(\"Forecast time (days)\"); ax.set_ylabel(\"ACC\")\n",
    "                    plt.show()\n",
    "\n",
    "                display(Markdown(\"‚úÖ Done\"))\n",
    "            except Exception as e:\n",
    "                display(Markdown(f\"‚ùå Error: `{e}`\"))\n",
    "\n",
    "    run_btn.on_click(on_run)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIFS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
